{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32cfd075-1671-4b72-942c-b3233e8833bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing the true function and decision boundary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"720\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training with 4000 samples:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  6.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"720\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Define the function f(x1, x2) - using a complex non-linear function\n",
    "def f(x1, x2):\n",
    "    \"\"\"A non-linear function combining sinusoidal and quadratic terms\"\"\"\n",
    "    return np.sin(3 * x1) + 0.5 * np.cos(4 * x2) + 0.5 * (x1**2 - x2**2)\n",
    "\n",
    "# Define the threshold T for binary classification\n",
    "T = 0.5\n",
    "\n",
    "# Generate random samples in the unit square\n",
    "def generate_samples(n_samples):\n",
    "    \"\"\"Generate random samples in the unit square [-1, 1] × [-1, 1]\"\"\"\n",
    "    X = np.random.uniform(-1, 1, (n_samples, 2))\n",
    "    x1, x2 = X[:, 0], X[:, 1]\n",
    "    y_values = np.array([f(x1i, x2i) for x1i, x2i in zip(x1, x2)])\n",
    "    y = (y_values >= T).astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Build sequential model with configurable hidden layers\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer with sigmoid activation for binary classification\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute predictions for a grid of points\n",
    "def compute_predictions(model, n_points=100):\n",
    "    \"\"\"Compute model predictions on a grid\"\"\"\n",
    "    x1_grid = np.linspace(-1, 1, n_points)\n",
    "    x2_grid = np.linspace(-1, 1, n_points)\n",
    "    X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "    grid_points = np.vstack([X1.ravel(), X2.ravel()]).T\n",
    "    \n",
    "    # Get model predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        grid_points_tensor = torch.FloatTensor(grid_points)\n",
    "        predictions = model(grid_points_tensor).numpy().flatten()\n",
    "    \n",
    "    # Reshape predictions for visualization\n",
    "    pred_Z = predictions.reshape(X1.shape)\n",
    "    \n",
    "    return x1_grid, x2_grid, pred_Z\n",
    "\n",
    "# Function to train model and save snapshots at specified intervals\n",
    "def train_model_with_snapshots(X_train, y_train, save_epochs, max_epochs):\n",
    "    \"\"\"Train the model and save snapshots at specified epochs\"\"\"\n",
    "    # Model parameters\n",
    "    input_size = 2\n",
    "    hidden_sizes = [20,]*5\n",
    "    output_size = 1\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 32\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "    \n",
    "    # Create and initialize model\n",
    "    model = MLP(input_size, hidden_sizes, output_size)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Dictionary to store model snapshots\n",
    "    model_snapshots = {}\n",
    "    \n",
    "    # Save initial untrained model\n",
    "    model_snapshots[0] = copy.deepcopy(model)\n",
    "    \n",
    "    # Track losses\n",
    "    losses = []\n",
    "    epoch_nums = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(1, max_epochs + 1)):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        epoch_nums.append(epoch)\n",
    "        \n",
    "        # Save model snapshot if it's in the save_epochs list\n",
    "        if epoch in save_epochs:\n",
    "            model_snapshots[epoch] = copy.deepcopy(model)\n",
    "    \n",
    "    # Create loss plot\n",
    "    loss_fig = go.Figure()\n",
    "    loss_fig.add_trace(go.Scatter(\n",
    "        x=epoch_nums,\n",
    "        y=losses,\n",
    "        mode='lines+markers',\n",
    "        name='Training Loss'\n",
    "    ))\n",
    "    \n",
    "    loss_fig.update_layout(\n",
    "        title=f'Training Loss (n={len(X_train)})',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='Binary Cross-Entropy Loss',\n",
    "        width=800,\n",
    "        height=400,\n",
    "    )\n",
    "    \n",
    "    return model_snapshots, loss_fig\n",
    "\n",
    "# Function to visualize the true function with a 3D surface plot\n",
    "def visualize_true_function():\n",
    "    \"\"\"Visualize the true function and its decision boundary using Plotly Surface plot\"\"\"\n",
    "    n_points = 100\n",
    "    x1_grid = np.linspace(-1, 1, n_points)\n",
    "    x2_grid = np.linspace(-1, 1, n_points)\n",
    "    X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "    \n",
    "    # Calculate function values\n",
    "    true_Z = np.zeros((n_points, n_points))\n",
    "    for i in range(n_points):\n",
    "        for j in range(n_points):\n",
    "            true_Z[i, j] = f(X1[i, j], X2[i, j])\n",
    "    \n",
    "    # Create 3D surface plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add surface for function values\n",
    "    fig.add_trace(go.Surface(\n",
    "        z=true_Z,\n",
    "        x=X1,\n",
    "        y=X2,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.9,\n",
    "        colorbar=dict(title='f(x1, x2) values'),\n",
    "        name='Function Values'\n",
    "    ))\n",
    "    \n",
    "    # Add a plane at z=T to visualize decision boundary\n",
    "    x_plane = np.linspace(-1, 1, 2)\n",
    "    y_plane = np.linspace(-1, 1, 2)\n",
    "    X_plane, Y_plane = np.meshgrid(x_plane, y_plane)\n",
    "    Z_plane = np.ones(X_plane.shape) * T\n",
    "    \n",
    "    fig.add_trace(go.Surface(\n",
    "        z=Z_plane,\n",
    "        x=X_plane,\n",
    "        y=Y_plane,\n",
    "        colorscale=[[0, 'rgba(255, 0, 0, 0.3)'], [1, 'rgba(255, 0, 0, 0.3)']],\n",
    "        showscale=False,\n",
    "        name='Decision Boundary'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'True Function f(x1, x2) with Decision Boundary (T = {T})',\n",
    "        scene=dict(\n",
    "            xaxis_title='x1',\n",
    "            yaxis_title='x2',\n",
    "            zaxis_title='f(x1, x2)',\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.87, y=0.88, z=1.5)\n",
    "            ),\n",
    "            annotations=[\n",
    "                dict(\n",
    "                    showarrow=False,\n",
    "                    x=0.1,\n",
    "                    y=0.1,\n",
    "                    z=T,\n",
    "                    text=\"Decision Boundary (T=0.5)\",\n",
    "                    xanchor=\"left\",\n",
    "                    xshift=10,\n",
    "                    opacity=0.7\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        width=800,\n",
    "        height=700,\n",
    "    )\n",
    "    \n",
    "    # Add contours projection to the surface\n",
    "    fig.update_traces(\n",
    "        contours_z=dict(\n",
    "            show=True, \n",
    "            usecolormap=True,\n",
    "            highlightcolor=\"limegreen\", \n",
    "            project_z=True\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create an interactive 3D visualization with epoch slider\n",
    "def create_interactive_visualization(model_snapshots, X_train, y_train, n_samples):\n",
    "    \"\"\"Create an interactive 3D visualization with an epoch slider\"\"\"\n",
    "    epochs = sorted(list(model_snapshots.keys()))\n",
    "    \n",
    "    # Pre-compute predictions for all epochs\n",
    "    predictions_by_epoch = {}\n",
    "    for epoch, model in model_snapshots.items():\n",
    "        n_points = 50  # Reduced for performance\n",
    "        x1_grid = np.linspace(-1, 1, n_points)\n",
    "        x2_grid = np.linspace(-1, 1, n_points)\n",
    "        X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "        grid_points = np.vstack([X1.ravel(), X2.ravel()]).T\n",
    "        \n",
    "        # Get model predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            grid_points_tensor = torch.FloatTensor(grid_points)\n",
    "            predictions = model(grid_points_tensor).numpy().flatten()\n",
    "        \n",
    "        # Reshape predictions for visualization\n",
    "        pred_Z = predictions.reshape(X1.shape)\n",
    "        predictions_by_epoch[epoch] = (X1, X2, pred_Z)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Initial epoch to display\n",
    "    initial_epoch = epochs[0]\n",
    "    X1, X2, pred_Z = predictions_by_epoch[initial_epoch]\n",
    "    \n",
    "    # Add surface for prediction probabilities\n",
    "    surface = go.Surface(\n",
    "        z=pred_Z,\n",
    "        x=X1,\n",
    "        y=X2,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.9,\n",
    "        colorbar=dict(title='Probability'),\n",
    "        name='Prediction Probabilities'\n",
    "    )\n",
    "    fig.add_trace(surface)\n",
    "    \n",
    "    # Add a plane at z=0.5 to visualize decision boundary\n",
    "    x_plane = np.linspace(-1, 1, 2)\n",
    "    y_plane = np.linspace(-1, 1, 2)\n",
    "    X_plane, Y_plane = np.meshgrid(x_plane, y_plane)\n",
    "    Z_plane = np.ones(X_plane.shape) * 0.5\n",
    "    \n",
    "    fig.add_trace(go.Surface(\n",
    "        z=Z_plane,\n",
    "        x=X_plane,\n",
    "        y=Y_plane,\n",
    "        colorscale=[[0, 'rgba(255, 0, 0, 0.3)'], [1, 'rgba(255, 0, 0, 0.3)']],\n",
    "        showscale=False,\n",
    "        name='Decision Boundary'\n",
    "    ))\n",
    "    \n",
    "    # Split into positive and negative examples for different colors\n",
    "    pos_samples = X_train[y_train.astype(bool)]\n",
    "    neg_samples = X_train[~y_train.astype(bool)]\n",
    "    \n",
    "    # Add positive samples as 3D scatter points\n",
    "    if len(pos_samples) > 0:\n",
    "        pos_scatter = go.Scatter3d(\n",
    "            x=pos_samples[:, 0],\n",
    "            y=pos_samples[:, 1],\n",
    "            z=np.ones(len(pos_samples)),  # Place points at z=1\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color='orange',\n",
    "                size=4,\n",
    "                line=dict(color='black', width=0.5)\n",
    "            ),\n",
    "            name='y = 1'\n",
    "        )\n",
    "        fig.add_trace(pos_scatter)\n",
    "    \n",
    "    # Add negative samples as 3D scatter points\n",
    "    if len(neg_samples) > 0:\n",
    "        neg_scatter = go.Scatter3d(\n",
    "            x=neg_samples[:, 0],\n",
    "            y=neg_samples[:, 1],\n",
    "            z=np.zeros(len(neg_samples)),  # Place points at z=0\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color='blue',\n",
    "                size=4,\n",
    "                line=dict(color='black', width=0.5)\n",
    "            ),\n",
    "            name='y = 0'\n",
    "        )\n",
    "        fig.add_trace(neg_scatter)\n",
    "    \n",
    "    # Create slider steps\n",
    "    steps = []\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        X1, X2, pred_Z = predictions_by_epoch[epoch]\n",
    "        \n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            args=[\n",
    "                # Update z values for the surface\n",
    "                {\"z\": [pred_Z, Z_plane, None, None]},\n",
    "                # Keep everything else the same\n",
    "                {\"title\": f\"MLP Predictions - n={n_samples}, Epoch {epoch}\"}\n",
    "            ],\n",
    "            label=str(epoch)\n",
    "        )\n",
    "        steps.append(step)\n",
    "    \n",
    "    # Create slider\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Epoch: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps\n",
    "    )]\n",
    "    \n",
    "    # Add contours projection to the surface\n",
    "    fig.update_traces(\n",
    "        contours_z=dict(\n",
    "            show=True, \n",
    "            usecolormap=True,\n",
    "            highlightcolor=\"limegreen\", \n",
    "            project_z=True\n",
    "        ),\n",
    "        selector=dict(type='surface')\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"MLP Predictions - n={n_samples}, Epoch {initial_epoch}\",\n",
    "        scene=dict(\n",
    "            xaxis_title='x1',\n",
    "            yaxis_title='x2',\n",
    "            zaxis_title='Probability',\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.87, y=0.88, z=1.5)\n",
    "            )\n",
    "        ),\n",
    "        width=800,\n",
    "        height=700,\n",
    "        sliders=sliders\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function to run the experiment with interactive visualizations\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Run the experiment with interactive epoch sliders for each sample size\"\"\"\n",
    "    # First, visualize the true function\n",
    "    print(\"Visualizing the true function and decision boundary:\")\n",
    "    true_func_fig = visualize_true_function()\n",
    "    true_func_fig.show()\n",
    "    \n",
    "    # Sample sizes to test\n",
    "    sample_sizes = [4000]\n",
    "    \n",
    "    # Set the maximum number of epochs\n",
    "    max_epochs = 50\n",
    "    \n",
    "    # Define epochs to save (more frequent at the beginning, less frequent later)\n",
    "    save_epochs = list(range(0, 21, 5)) + list(range(30, 101, 10)) + list(range(120, max_epochs + 1, 20))\n",
    "    \n",
    "    # Process each sample size\n",
    "    for n_samples in sample_sizes:\n",
    "        print(f\"\\n\\nTraining with {n_samples} samples:\")\n",
    "        X_train, y_train = generate_samples(n_samples)\n",
    "        \n",
    "        # Train model and capture snapshots\n",
    "        model_snapshots, loss_fig = train_model_with_snapshots(X_train, y_train, save_epochs, max_epochs)\n",
    "        \n",
    "        # Create interactive visualization\n",
    "        interactive_fig = create_interactive_visualization(model_snapshots, X_train, y_train, n_samples)\n",
    "        \n",
    "        # Display the figures\n",
    "        interactive_fig.show()\n",
    "        loss_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8792a-d060-417d-b2c3-69fe9529084e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660134e7-a45f-4e3b-b99c-aaa0e7b81f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99195d-be92-42a4-94e7-38df2710b8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fad18-18ea-471a-9d65-f06c5981cb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4802580-31fb-42da-97e3-019c322c9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models and capturing snapshots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████                                                                                    | 16/100 [00:00<00:00, 153.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.2761\n",
      "Epoch 20/100, Loss: 0.2112\n",
      "Epoch 30/100, Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████████                                                                  | 34/100 [00:00<00:00, 164.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████                              | 70/100 [00:00<00:00, 169.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1750\n",
      "Epoch 60/100, Loss: 0.1400\n",
      "Epoch 70/100, Loss: 0.1648\n",
      "Epoch 80/100, Loss: 0.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 168.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.1228\n",
      "Epoch 100/100, Loss: 0.1044\n",
      "Extracting hidden layer activations...\n",
      "Extracting activations for epoch 0\n",
      "Extracting activations for epoch 10\n",
      "Extracting activations for epoch 20\n",
      "Extracting activations for epoch 30\n",
      "Extracting activations for epoch 40\n",
      "Extracting activations for epoch 50\n",
      "Extracting activations for epoch 60\n",
      "Extracting activations for epoch 70\n",
      "Extracting activations for epoch 80\n",
      "Extracting activations for epoch 90\n",
      "Extracting activations for epoch 100\n",
      "Creating interactive visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing visualization data: 100%|███████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 464.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Define the function f(x1, x2) - using a complex non-linear function\n",
    "def f(x1, x2):\n",
    "    \"\"\"A non-linear function combining sinusoidal and quadratic terms\"\"\"\n",
    "    return np.sin(3 * x1) + 0.5 * np.cos(4 * x2) + 0.5 * (x1**2 - x2**2)\n",
    "\n",
    "# Define the threshold T for binary classification\n",
    "T = 0.5\n",
    "\n",
    "# Generate random samples in the unit square\n",
    "def generate_samples(n_samples):\n",
    "    \"\"\"Generate random samples in the unit square [-1, 1] × [-1, 1]\"\"\"\n",
    "    X = np.random.uniform(-1, 1, (n_samples, 2))\n",
    "    x1, x2 = X[:, 0], X[:, 1]\n",
    "    y_values = np.array([f(x1i, x2i) for x1i, x2i in zip(x1, x2)])\n",
    "    y = (y_values >= T).astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the MLP model with named modules\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Use ModuleDict for named modules\n",
    "        self.layers = nn.ModuleDict()\n",
    "        \n",
    "        # Store layer names and dimensions for reference\n",
    "        self.layer_info = {\n",
    "            'input': {'name': 'Input Layer', 'size': input_size}\n",
    "        }\n",
    "        \n",
    "        # Add hidden layers\n",
    "        prev_size = input_size\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            linear_name = f'linear{i+1}'\n",
    "            relu_name = f'relu{i+1}'\n",
    "            \n",
    "            self.layers[linear_name] = nn.Linear(prev_size, hidden_size)\n",
    "            self.layers[relu_name] = nn.ReLU()\n",
    "            \n",
    "            self.layer_info[linear_name] = {'name': f'Hidden Layer {i+1} (Linear)', 'size': hidden_size}\n",
    "            self.layer_info[relu_name] = {'name': f'Hidden Layer {i+1} (ReLU)', 'size': hidden_size}\n",
    "            \n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Add output layer\n",
    "        output_linear = f'linear{len(hidden_sizes)+1}'\n",
    "        self.layers[output_linear] = nn.Linear(prev_size, output_size)\n",
    "        self.layers['sigmoid'] = nn.Sigmoid()\n",
    "        \n",
    "        self.layer_info[output_linear] = {'name': 'Output Layer (Linear)', 'size': output_size}\n",
    "        self.layer_info['sigmoid'] = {'name': 'Output Layer (Sigmoid)', 'size': output_size}\n",
    "        \n",
    "        # Store layer names in order for forward pass\n",
    "        self.layer_names = ['input'] + list(self.layers.keys())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        activations = {'input': x}\n",
    "        \n",
    "        for name in self.layer_names[1:]:  # Skip input layer\n",
    "            x = self.layers[name](x)\n",
    "            activations[name] = x\n",
    "        \n",
    "        return x, activations\n",
    "\n",
    "# Function to train model and save snapshots at specified intervals\n",
    "def train_model_with_snapshots(X_train, y_train, save_epochs, max_epochs):\n",
    "    \"\"\"Train the model and save snapshots at specified epochs\"\"\"\n",
    "    # Model parameters\n",
    "    input_size = 2\n",
    "    hidden_sizes = [20, 10]\n",
    "    output_size = 1\n",
    "    learning_rate = 0.01\n",
    "    batch_size = 32\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "    \n",
    "    # Create and initialize model\n",
    "    model = MLP(input_size, hidden_sizes, output_size)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Dictionary to store model snapshots\n",
    "    model_snapshots = {}\n",
    "    \n",
    "    # Save initial untrained model\n",
    "    model_snapshots[0] = copy.deepcopy(model)\n",
    "    \n",
    "    # Track losses\n",
    "    losses = []\n",
    "    epoch_nums = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(1, max_epochs + 1)):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in dataloader:\n",
    "            # Forward pass - now returns both outputs and activations\n",
    "            outputs, _ = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        epoch_nums.append(epoch)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{max_epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Save model snapshot if it's in the save_epochs list\n",
    "        if epoch in save_epochs:\n",
    "            model_snapshots[epoch] = copy.deepcopy(model)\n",
    "    \n",
    "    # Create loss plot\n",
    "    loss_fig = go.Figure()\n",
    "    loss_fig.add_trace(go.Scatter(\n",
    "        x=epoch_nums,\n",
    "        y=losses,\n",
    "        mode='lines+markers',\n",
    "        name='Training Loss'\n",
    "    ))\n",
    "    \n",
    "    loss_fig.update_layout(\n",
    "        title=f'Training Loss (n={len(X_train)})',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='Binary Cross-Entropy Loss',\n",
    "        width=800,\n",
    "        height=400,\n",
    "    )\n",
    "    \n",
    "    return model_snapshots, loss_fig\n",
    "\n",
    "# Function to create scatter plot grid of hidden features\n",
    "def plot_column_scatter_grid(data, y_labels, column_names=None, \n",
    "                            marker_size=5, opacity=0.7,\n",
    "                            height=800, width=800,\n",
    "                            title=\"Scatter Plot Matrix\",\n",
    "                            color_map=None):\n",
    "    # Ensure data is a numpy array\n",
    "    data = np.asarray(data)\n",
    "    y_labels = np.asarray(y_labels)\n",
    "    \n",
    "    # Get number of columns\n",
    "    n_cols = data.shape[1]\n",
    "    \n",
    "    # Generate default column names if not provided\n",
    "    if column_names is None:\n",
    "        column_names = [f\"Feature {i+1}\" for i in range(n_cols)]\n",
    "    \n",
    "    # Ensure we have the right number of column names\n",
    "    if len(column_names) != n_cols:\n",
    "        raise ValueError(f\"Number of column names ({len(column_names)}) \"\n",
    "                         f\"doesn't match number of columns in data ({n_cols})\")\n",
    "    \n",
    "    # Ensure we have the right number of labels\n",
    "    if len(y_labels) != data.shape[0]:\n",
    "        raise ValueError(f\"Number of labels ({len(y_labels)}) \"\n",
    "                         f\"doesn't match number of samples in data ({data.shape[0]})\")\n",
    "    \n",
    "    # Get unique classes\n",
    "    unique_classes = np.unique(y_labels)\n",
    "    \n",
    "    # Create color map if not provided\n",
    "    if color_map is None:\n",
    "        default_colors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880']\n",
    "        color_map = {cls: default_colors[i % len(default_colors)] for i, cls in enumerate(unique_classes)}\n",
    "    \n",
    "    # Create subplot grid\n",
    "    fig = make_subplots(\n",
    "        rows=n_cols, \n",
    "        cols=n_cols,\n",
    "        shared_xaxes=False, \n",
    "        shared_yaxes=False\n",
    "    )\n",
    "    \n",
    "    # Loop through all pairs of columns\n",
    "    for i in range(n_cols):\n",
    "        for j in range(n_cols):\n",
    "            # For each class, add a separate trace\n",
    "            for cls in unique_classes:\n",
    "                # Get indices for this class\n",
    "                idx = y_labels == cls\n",
    "                \n",
    "                # Skip if no samples for this class\n",
    "                if not np.any(idx):\n",
    "                    continue\n",
    "                \n",
    "                # Extract data for this class and column pair\n",
    "                x = data[idx, j]  # Column j will be on x-axis\n",
    "                y = data[idx, i]  # Column i will be on y-axis\n",
    "                \n",
    "                # Add scatter plot trace for this class\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=x,\n",
    "                        y=y,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=marker_size,\n",
    "                            opacity=opacity,\n",
    "                            color=color_map[cls]\n",
    "                        ),\n",
    "                        name=f'Class {cls}',\n",
    "                        # Only add legend for the first subplot\n",
    "                        showlegend=(i==0 and j==0)\n",
    "                    ),\n",
    "                    row=i+1, col=j+1\n",
    "                )\n",
    "            \n",
    "            # Add axis labels\n",
    "            if i == n_cols-1:  # Bottom row\n",
    "                fig.update_xaxes(title_text=column_names[j], row=i+1, col=j+1)\n",
    "            if j == 0:  # First column\n",
    "                fig.update_yaxes(title_text=column_names[i], row=i+1, col=j+1)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=height, \n",
    "        width=width,\n",
    "        title_text=title,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Function to extract hidden layer activations for all epochs and layers\n",
    "def extract_hidden_layers(model_snapshots, X_train):\n",
    "    \"\"\"Extract hidden layer activations for all model snapshots\"\"\"\n",
    "    hidden_activations = {}\n",
    "    \n",
    "    for epoch, model in model_snapshots.items():\n",
    "        print(f\"Extracting activations for epoch {epoch}\")\n",
    "        \n",
    "        x = torch.FloatTensor(X_train)\n",
    "        _, activations_dict = model(x)  # Get activations directly from model forward pass\n",
    "        \n",
    "        # Convert tensor activations to numpy arrays\n",
    "        activations_dict = {\n",
    "            layer_name: act.detach().numpy() \n",
    "            for layer_name, act in activations_dict.items()\n",
    "        }\n",
    "        \n",
    "        # Store activations for this epoch\n",
    "        hidden_activations[epoch] = activations_dict\n",
    "    \n",
    "    return hidden_activations\n",
    "\n",
    "# Function to sample features from activation data\n",
    "def sample_features(data, max_features, rng=None):\n",
    "    \"\"\"Sample max_features from data if there are more features than max_features\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.RandomState(42)  # Use fixed seed for reproducibility\n",
    "        \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    if n_features <= max_features:\n",
    "        # Use all features if fewer than max_features\n",
    "        return data, list(range(n_features))\n",
    "    \n",
    "    # Randomly sample feature indices without replacement\n",
    "    feature_indices = rng.choice(n_features, max_features, replace=False)\n",
    "    feature_indices.sort()  # Sort for consistency in visualization\n",
    "    \n",
    "    # Select sampled features\n",
    "    sampled_data = data[:, feature_indices]\n",
    "    \n",
    "    return sampled_data, feature_indices\n",
    "\n",
    "# Function to create interactive visualization with layer and epoch sliders\n",
    "def create_dual_slider_visualization(hidden_activations, y_train, max_features=5):\n",
    "    \"\"\"Create an interactive visualization with sliders for both epoch and layer\"\"\"\n",
    "    # Get available epochs and layers\n",
    "    epochs = sorted(list(hidden_activations.keys()))\n",
    "    \n",
    "    # Get layer names (should be same for all epochs)\n",
    "    layer_names = list(hidden_activations[epochs[0]].keys())\n",
    "    \n",
    "    # Create a random number generator for consistent feature sampling\n",
    "    rng = np.random.RandomState(42)\n",
    "    \n",
    "    # Use first epoch, first layer data to determine dimensions\n",
    "    initial_data = hidden_activations[epochs[0]][layer_names[0]]\n",
    "    \n",
    "    # Initial layer: use the first hidden layer if available\n",
    "    initial_layer_name = layer_names[min(1, len(layer_names) - 1)]\n",
    "    \n",
    "    # Sample features and create feature names for each layer\n",
    "    layer_features = {}\n",
    "    for layer_name in layer_names:\n",
    "        layer_data = hidden_activations[epochs[0]][layer_name]\n",
    "        sampled_data, feature_indices = sample_features(layer_data, max_features, rng)\n",
    "        layer_features[layer_name] = {\n",
    "            'indices': feature_indices,\n",
    "            'names': [f\"Feature {idx+1}\" for idx in feature_indices]\n",
    "        }\n",
    "    \n",
    "    # Create human-readable layer names without relying on model.layer_info\n",
    "    layer_display_names = {}\n",
    "    for layer_name in layer_names:\n",
    "        if layer_name == 'input':\n",
    "            layer_display_names[layer_name] = 'Input Layer'\n",
    "        elif 'linear' in layer_name:\n",
    "            # Extract number from linear layer name, if any\n",
    "            num = ''.join(filter(str.isdigit, layer_name))\n",
    "            if num:\n",
    "                layer_display_names[layer_name] = f'Hidden Layer {num} (Linear)'\n",
    "            else:\n",
    "                layer_display_names[layer_name] = 'Output Layer (Linear)'\n",
    "        elif 'relu' in layer_name:\n",
    "            # Extract number from relu layer name, if any\n",
    "            num = ''.join(filter(str.isdigit, layer_name))\n",
    "            if num:\n",
    "                layer_display_names[layer_name] = f'Hidden Layer {num} (ReLU)'\n",
    "            else:\n",
    "                layer_display_names[layer_name] = 'ReLU Activation'\n",
    "        elif 'sigmoid' in layer_name:\n",
    "            layer_display_names[layer_name] = 'Output Layer (Sigmoid)'\n",
    "        else:\n",
    "            # Default case - capitalize the layer name\n",
    "            layer_display_names[layer_name] = layer_name.capitalize()\n",
    "    \n",
    "    # Create initial visualization\n",
    "    initial_data = hidden_activations[epochs[0]][initial_layer_name]\n",
    "    sampled_data, _ = sample_features(initial_data, max_features, rng)\n",
    "    feature_names = layer_features[initial_layer_name]['names']\n",
    "    \n",
    "    # Create base figure with initial data\n",
    "    fig = plot_column_scatter_grid(\n",
    "        sampled_data, \n",
    "        y_train,\n",
    "        column_names=feature_names,\n",
    "        title=f\"{layer_display_names[initial_layer_name]} Features (Epoch {epochs[0]})\"\n",
    "    )\n",
    "    \n",
    "    # Create a lookup table for all possible scatter traces\n",
    "    # This is to efficiently update the figure without recreating it each time\n",
    "    trace_lookup = {}\n",
    "    \n",
    "    for epoch in tqdm(epochs, desc=\"Preparing visualization data\"):\n",
    "        for layer_name in layer_names:\n",
    "            layer_data = hidden_activations[epoch][layer_name]\n",
    "            feature_indices = layer_features[layer_name]['indices']\n",
    "            \n",
    "            # Sample features\n",
    "            sampled_data, _ = sample_features(layer_data, max_features, rng)\n",
    "            n_features = sampled_data.shape[1]\n",
    "            \n",
    "            # Skip if layer has no dimensions or no features\n",
    "            if n_features == 0:\n",
    "                continue\n",
    "                \n",
    "            # Create a dict to store scatter data for this epoch and layer\n",
    "            trace_lookup[(epoch, layer_name)] = []\n",
    "            \n",
    "            # Loop through all pairs of features\n",
    "            for i in range(n_features):\n",
    "                for j in range(n_features):\n",
    "                    # For each class\n",
    "                    unique_classes = np.unique(y_train)\n",
    "                    \n",
    "                    for cls in unique_classes:\n",
    "                        # Get indices for this class\n",
    "                        idx = y_train == cls\n",
    "                        \n",
    "                        # Extract data for this class and feature pair\n",
    "                        x = sampled_data[idx, j]\n",
    "                        y = sampled_data[idx, i]\n",
    "                        \n",
    "                        # Store x and y data for this trace\n",
    "                        trace_lookup[(epoch, layer_name)].append({\n",
    "                            'row': i+1, \n",
    "                            'col': j+1, \n",
    "                            'x': x, \n",
    "                            'y': y,\n",
    "                            'class': cls\n",
    "                        })\n",
    "    \n",
    "    # Create frames for each combination of epoch and layer\n",
    "    frames = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        for layer_name in layer_names:\n",
    "            # Skip if this combination doesn't have data\n",
    "            if (epoch, layer_name) not in trace_lookup:\n",
    "                continue\n",
    "                \n",
    "            n_features = len(layer_features[layer_name]['indices'])\n",
    "            frame_traces = []\n",
    "            \n",
    "            # Create traces for each subplot position\n",
    "            for i in range(n_features):\n",
    "                for j in range(n_features):\n",
    "                    for cls_idx, cls in enumerate(np.unique(y_train)):\n",
    "                        # Find the corresponding trace data\n",
    "                        trace_idx = (i * n_features + j) * len(np.unique(y_train)) + cls_idx\n",
    "                        \n",
    "                        # Skip if index out of range\n",
    "                        if trace_idx >= len(trace_lookup[(epoch, layer_name)]):\n",
    "                            continue\n",
    "                            \n",
    "                        trace_data = trace_lookup[(epoch, layer_name)][trace_idx]\n",
    "                        \n",
    "                        # Create the trace for this frame\n",
    "                        trace = go.Scatter(\n",
    "                            x=trace_data['x'],\n",
    "                            y=trace_data['y'],\n",
    "                            mode='markers',\n",
    "                            showlegend=False  # Legend is from base figure\n",
    "                        )\n",
    "                        \n",
    "                        frame_traces.append(trace)\n",
    "            \n",
    "            # Create a frame for this epoch and layer\n",
    "            frame = go.Frame(\n",
    "                data=frame_traces,\n",
    "                name=f\"epoch{epoch}_layer{layer_name}\",\n",
    "                layout=go.Layout(title=f\"{layer_display_names[layer_name]} Features (Epoch {epoch})\")\n",
    "            )\n",
    "            frames.append(frame)\n",
    "    \n",
    "    # Add frames to the figure\n",
    "    fig.frames = frames\n",
    "    \n",
    "    # Create sliders for epoch and layer\n",
    "    epoch_steps = []\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        step = {\n",
    "            \"args\": [\n",
    "                [f\"epoch{epoch}_layer{initial_layer_name}\"],  # First show initial layer with this epoch\n",
    "                {\"frame\": {\"duration\": 300, \"redraw\": True}, \"mode\": \"immediate\"}\n",
    "            ],\n",
    "            \"label\": str(epoch),\n",
    "            \"method\": \"animate\"\n",
    "        }\n",
    "        epoch_steps.append(step)\n",
    "    \n",
    "    layer_steps = []\n",
    "    for layer_name in layer_names:\n",
    "        step = {\n",
    "            \"args\": [\n",
    "                [f\"epoch{epochs[0]}_layer{layer_name}\"],  # First show initial epoch with this layer\n",
    "                {\"frame\": {\"duration\": 300, \"redraw\": True}, \"mode\": \"immediate\"}\n",
    "            ],\n",
    "            \"label\": layer_display_names[layer_name],\n",
    "            \"method\": \"animate\"\n",
    "        }\n",
    "        layer_steps.append(step)\n",
    "    \n",
    "    # Create sliders\n",
    "    sliders = [\n",
    "        {\n",
    "            \"active\": 0,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 16},\n",
    "                \"prefix\": \"Epoch: \",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"right\"\n",
    "            },\n",
    "            \"transition\": {\"duration\": 300},\n",
    "            \"pad\": {\"b\": 10, \"t\": 50},\n",
    "            \"len\": 0.9,\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 0,\n",
    "            \"steps\": epoch_steps\n",
    "        },\n",
    "        {\n",
    "            \"active\": layer_names.index(initial_layer_name),\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 16},\n",
    "                \"prefix\": \"Layer: \",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"right\"\n",
    "            },\n",
    "            \"transition\": {\"duration\": 300},\n",
    "            \"pad\": {\"b\": 10, \"t\": 120},\n",
    "            \"len\": 0.9,\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 0.1,\n",
    "            \"steps\": layer_steps\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Update layout with sliders\n",
    "    fig.update_layout(\n",
    "        sliders=sliders,\n",
    "        updatemenus=[\n",
    "            {\n",
    "                \"buttons\": [\n",
    "                    {\n",
    "                        \"args\": [None, {\"frame\": {\"duration\": 300, \"redraw\": True}, \"fromcurrent\": True}],\n",
    "                        \"label\": \"Play\",\n",
    "                        \"method\": \"animate\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\"}],\n",
    "                        \"label\": \"Pause\",\n",
    "                        \"method\": \"animate\"\n",
    "                    }\n",
    "                ],\n",
    "                \"direction\": \"left\",\n",
    "                \"pad\": {\"r\": 10, \"t\": 87},\n",
    "                \"showactive\": False,\n",
    "                \"type\": \"buttons\",\n",
    "                \"x\": 0.1,\n",
    "                \"xanchor\": \"right\",\n",
    "                \"y\": 0,\n",
    "                \"yanchor\": \"top\"\n",
    "            }\n",
    "        ],\n",
    "        # Extra margin at bottom for sliders\n",
    "        margin=dict(l=50, r=50, t=100, b=150)\n",
    "    )\n",
    "    \n",
    "    # Add interactive feature\n",
    "    fig.update_layout(\n",
    "        hovermode=\"closest\",\n",
    "        clickmode=\"event+select\"\n",
    "    )\n",
    "    \n",
    "    # Custom JavaScript for slider synchronization\n",
    "    fig.add_annotation(\n",
    "        text=\"Use sliders to explore features across epochs and layers\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=1.05,\n",
    "        showarrow=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function to run the experiment with dual-slider visualization\n",
    "def run_experiment_with_dual_sliders(max_features=5):\n",
    "    \"\"\"Run the experiment with dual sliders for epoch and layer\"\"\"\n",
    "    # Generate training data\n",
    "    n_samples = 200\n",
    "    X_train, y_train = generate_samples(n_samples)\n",
    "    \n",
    "    # Set the maximum number of epochs\n",
    "    max_epochs = 100\n",
    "    \n",
    "    # Define epochs to save\n",
    "    save_epochs = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    \n",
    "    # Train model and capture snapshots\n",
    "    print(\"Training models and capturing snapshots...\")\n",
    "    model_snapshots, loss_fig = train_model_with_snapshots(X_train, y_train, save_epochs, max_epochs)\n",
    "    \n",
    "    # Extract hidden layer activations for all epochs and layers\n",
    "    print(\"Extracting hidden layer activations...\")\n",
    "    hidden_activations = extract_hidden_layers(model_snapshots, X_train)\n",
    "    \n",
    "    # Create interactive visualization with dual sliders\n",
    "    print(\"Creating interactive visualization...\")\n",
    "    interactive_fig = create_dual_slider_visualization(hidden_activations, y_train, max_features=max_features)\n",
    "    \n",
    "    # Display the figures\n",
    "    loss_fig.show()\n",
    "    interactive_fig.show()\n",
    "    \n",
    "    return model_snapshots, hidden_activations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Make max_features configurable\n",
    "    max_features = 5  # Change this value to show more or fewer features\n",
    "    global model_snapshots  # Make this available to the visualization function\n",
    "    model_snapshots, hidden_activations = run_experiment_with_dual_sliders(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df9c85-ece2-4e8e-8cdb-492a327ad683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caa5e4-5cdb-42c8-8e53-8d0c78c98be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaa865d-8584-4291-9203-2c7715084f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_6.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Create a graph using NetworkX\n",
    "G = nx.random_geometric_graph(20, 0.2)\n",
    "\n",
    "# Get node positions\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Create edges\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.extend([x0, x1, None])\n",
    "    edge_y.extend([y0, y1, None])\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "# Create nodes\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlGnBu',\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title=dict(  # Change here: use title dict instead of titleside\n",
    "                text='Node Connections',\n",
    "                side='right'  # You can specify the side here\n",
    "            ),\n",
    "            xanchor='left'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Color nodes by number of connections\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append(f'# of connections: {len(adjacencies[1])}')\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='Network Graph',\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=20, l=5, r=5, t=40),\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "                ))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ec666-9e6f-490c-9761-a5211677ce9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
