{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c81a45-732b-4163-8f6f-ac906482375d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785eea59-7446-421b-81c3-44fa9f52bab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "=== Continual Learning Experiment (Sequential Training on Task Pairs) ===\n",
      "=== Before Training: Metrics ===\n",
      "erank_fc1: 354.1995\n",
      "erank_fc2: 321.8415\n",
      "avg_contrib_fc1: 1.2890\n",
      "avg_overall_fc1: 0.0465\n",
      "bc_avg_contrib_fc1: 64.7742\n",
      "bc_avg_overall_fc1: 2.3369\n",
      "avg_contrib_fc2: 0.0103\n",
      "avg_overall_fc2: 0.0009\n",
      "bc_avg_contrib_fc2: 0.5161\n",
      "bc_avg_overall_fc2: 0.0456\n",
      "\n",
      "=== Training on Task (classes [0, 1]) ===\n",
      "Task [0, 1] - Epoch 1/5: Loss = 0.7206\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 219.0818\n",
      "  erank_fc2: 101.4673\n",
      "  avg_contrib_fc1: 1.3036\n",
      "  avg_overall_fc1: 0.0470\n",
      "  bc_avg_contrib_fc1: 43.8918\n",
      "  bc_avg_overall_fc1: 1.5832\n",
      "  avg_contrib_fc2: 0.0111\n",
      "  avg_overall_fc2: 0.0010\n",
      "  bc_avg_contrib_fc2: 0.3732\n",
      "  bc_avg_overall_fc2: 0.0329\n",
      "Task [0, 1] - Epoch 2/5: Loss = 0.3747\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 239.7315\n",
      "  erank_fc2: 130.0002\n",
      "  avg_contrib_fc1: 1.3151\n",
      "  avg_overall_fc1: 0.0474\n",
      "  bc_avg_contrib_fc1: 33.3751\n",
      "  bc_avg_overall_fc1: 1.2036\n",
      "  avg_contrib_fc2: 0.0117\n",
      "  avg_overall_fc2: 0.0010\n",
      "  bc_avg_contrib_fc2: 0.2981\n",
      "  bc_avg_overall_fc2: 0.0263\n",
      "Task [0, 1] - Epoch 3/5: Loss = 0.3183\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 248.2770\n",
      "  erank_fc2: 144.0039\n",
      "  avg_contrib_fc1: 1.3261\n",
      "  avg_overall_fc1: 0.0478\n",
      "  bc_avg_contrib_fc1: 27.0573\n",
      "  bc_avg_overall_fc1: 0.9756\n",
      "  avg_contrib_fc2: 0.0124\n",
      "  avg_overall_fc2: 0.0011\n",
      "  bc_avg_contrib_fc2: 0.2530\n",
      "  bc_avg_overall_fc2: 0.0223\n",
      "Task [0, 1] - Epoch 4/5: Loss = 0.2814\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 255.1574\n",
      "  erank_fc2: 154.5701\n",
      "  avg_contrib_fc1: 1.3366\n",
      "  avg_overall_fc1: 0.0482\n",
      "  bc_avg_contrib_fc1: 22.8405\n",
      "  bc_avg_overall_fc1: 0.8234\n",
      "  avg_contrib_fc2: 0.0130\n",
      "  avg_overall_fc2: 0.0011\n",
      "  bc_avg_contrib_fc2: 0.2228\n",
      "  bc_avg_overall_fc2: 0.0196\n",
      "Task [0, 1] - Epoch 5/5: Loss = 0.2564\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 263.3577\n",
      "  erank_fc2: 166.9673\n",
      "  avg_contrib_fc1: 1.3465\n",
      "  avg_overall_fc1: 0.0485\n",
      "  bc_avg_contrib_fc1: 19.8210\n",
      "  bc_avg_overall_fc1: 0.7143\n",
      "  avg_contrib_fc2: 0.0137\n",
      "  avg_overall_fc2: 0.0012\n",
      "  bc_avg_contrib_fc2: 0.2010\n",
      "  bc_avg_overall_fc2: 0.0176\n",
      "\n",
      "=== Training on Task (classes [2, 3]) ===\n",
      "Task [2, 3] - Epoch 1/5: Loss = 1.2619\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 155.5916\n",
      "  erank_fc2: 57.6183\n",
      "  avg_contrib_fc1: 1.3716\n",
      "  avg_overall_fc1: 0.0494\n",
      "  bc_avg_contrib_fc1: 17.7546\n",
      "  bc_avg_overall_fc1: 0.6394\n",
      "  avg_contrib_fc2: 0.0146\n",
      "  avg_overall_fc2: 0.0013\n",
      "  bc_avg_contrib_fc2: 0.1892\n",
      "  bc_avg_overall_fc2: 0.0166\n",
      "Task [2, 3] - Epoch 2/5: Loss = 0.5318\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 168.3652\n",
      "  erank_fc2: 75.0923\n",
      "  avg_contrib_fc1: 1.3945\n",
      "  avg_overall_fc1: 0.0502\n",
      "  bc_avg_contrib_fc1: 16.1250\n",
      "  bc_avg_overall_fc1: 0.5803\n",
      "  avg_contrib_fc2: 0.0155\n",
      "  avg_overall_fc2: 0.0014\n",
      "  bc_avg_contrib_fc2: 0.1787\n",
      "  bc_avg_overall_fc2: 0.0156\n",
      "Task [2, 3] - Epoch 3/5: Loss = 0.5165\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 187.2692\n",
      "  erank_fc2: 103.5668\n",
      "  avg_contrib_fc1: 1.4135\n",
      "  avg_overall_fc1: 0.0508\n",
      "  bc_avg_contrib_fc1: 14.7823\n",
      "  bc_avg_overall_fc1: 0.5317\n",
      "  avg_contrib_fc2: 0.0160\n",
      "  avg_overall_fc2: 0.0014\n",
      "  bc_avg_contrib_fc2: 0.1678\n",
      "  bc_avg_overall_fc2: 0.0147\n",
      "Task [2, 3] - Epoch 4/5: Loss = 0.4879\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 201.7753\n",
      "  erank_fc2: 122.0848\n",
      "  avg_contrib_fc1: 1.4298\n",
      "  avg_overall_fc1: 0.0514\n",
      "  bc_avg_contrib_fc1: 13.6611\n",
      "  bc_avg_overall_fc1: 0.4911\n",
      "  avg_contrib_fc2: 0.0166\n",
      "  avg_overall_fc2: 0.0014\n",
      "  bc_avg_contrib_fc2: 0.1582\n",
      "  bc_avg_overall_fc2: 0.0138\n",
      "Task [2, 3] - Epoch 5/5: Loss = 0.4557\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 206.0813\n",
      "  erank_fc2: 123.5160\n",
      "  avg_contrib_fc1: 1.4458\n",
      "  avg_overall_fc1: 0.0519\n",
      "  bc_avg_contrib_fc1: 12.7250\n",
      "  bc_avg_overall_fc1: 0.4572\n",
      "  avg_contrib_fc2: 0.0171\n",
      "  avg_overall_fc2: 0.0015\n",
      "  bc_avg_contrib_fc2: 0.1506\n",
      "  bc_avg_overall_fc2: 0.0132\n",
      "\n",
      "=== Training on Task (classes [4, 5]) ===\n",
      "Task [4, 5] - Epoch 1/5: Loss = 1.2884\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 157.8352\n",
      "  erank_fc2: 30.4641\n",
      "  avg_contrib_fc1: 1.4693\n",
      "  avg_overall_fc1: 0.0527\n",
      "  bc_avg_contrib_fc1: 11.9967\n",
      "  bc_avg_overall_fc1: 0.4305\n",
      "  avg_contrib_fc2: 0.0180\n",
      "  avg_overall_fc2: 0.0016\n",
      "  bc_avg_contrib_fc2: 0.1471\n",
      "  bc_avg_overall_fc2: 0.0128\n",
      "Task [4, 5] - Epoch 2/5: Loss = 0.5029\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 178.3122\n",
      "  erank_fc2: 51.8523\n",
      "  avg_contrib_fc1: 1.4887\n",
      "  avg_overall_fc1: 0.0534\n",
      "  bc_avg_contrib_fc1: 11.3423\n",
      "  bc_avg_overall_fc1: 0.4066\n",
      "  avg_contrib_fc2: 0.0186\n",
      "  avg_overall_fc2: 0.0016\n",
      "  bc_avg_contrib_fc2: 0.1418\n",
      "  bc_avg_overall_fc2: 0.0123\n",
      "Task [4, 5] - Epoch 3/5: Loss = 0.4369\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 183.7555\n",
      "  erank_fc2: 56.7266\n",
      "  avg_contrib_fc1: 1.5079\n",
      "  avg_overall_fc1: 0.0540\n",
      "  bc_avg_contrib_fc1: 10.7752\n",
      "  bc_avg_overall_fc1: 0.3859\n",
      "  avg_contrib_fc2: 0.0192\n",
      "  avg_overall_fc2: 0.0017\n",
      "  bc_avg_contrib_fc2: 0.1374\n",
      "  bc_avg_overall_fc2: 0.0119\n",
      "Task [4, 5] - Epoch 4/5: Loss = 0.4146\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 190.6163\n",
      "  erank_fc2: 62.9851\n",
      "  avg_contrib_fc1: 1.5259\n",
      "  avg_overall_fc1: 0.0546\n",
      "  bc_avg_contrib_fc1: 10.2724\n",
      "  bc_avg_overall_fc1: 0.3676\n",
      "  avg_contrib_fc2: 0.0198\n",
      "  avg_overall_fc2: 0.0017\n",
      "  bc_avg_contrib_fc2: 0.1334\n",
      "  bc_avg_overall_fc2: 0.0115\n",
      "Task [4, 5] - Epoch 5/5: Loss = 0.3837\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 196.4851\n",
      "  erank_fc2: 67.8545\n",
      "  avg_contrib_fc1: 1.5434\n",
      "  avg_overall_fc1: 0.0552\n",
      "  bc_avg_contrib_fc1: 9.8268\n",
      "  bc_avg_overall_fc1: 0.3513\n",
      "  avg_contrib_fc2: 0.0204\n",
      "  avg_overall_fc2: 0.0018\n",
      "  bc_avg_contrib_fc2: 0.1298\n",
      "  bc_avg_overall_fc2: 0.0112\n",
      "\n",
      "=== Training on Task (classes [6, 7]) ===\n",
      "Task [6, 7] - Epoch 1/5: Loss = 1.4450\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 131.5036\n",
      "  erank_fc2: 22.9842\n",
      "  avg_contrib_fc1: 1.5727\n",
      "  avg_overall_fc1: 0.0561\n",
      "  bc_avg_contrib_fc1: 9.5038\n",
      "  bc_avg_overall_fc1: 0.3390\n",
      "  avg_contrib_fc2: 0.0214\n",
      "  avg_overall_fc2: 0.0018\n",
      "  bc_avg_contrib_fc2: 0.1295\n",
      "  bc_avg_overall_fc2: 0.0111\n",
      "Task [6, 7] - Epoch 2/5: Loss = 0.4802\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 152.2042\n",
      "  erank_fc2: 45.5237\n",
      "  avg_contrib_fc1: 1.5981\n",
      "  avg_overall_fc1: 0.0569\n",
      "  bc_avg_contrib_fc1: 9.1934\n",
      "  bc_avg_overall_fc1: 0.3274\n",
      "  avg_contrib_fc2: 0.0220\n",
      "  avg_overall_fc2: 0.0019\n",
      "  bc_avg_contrib_fc2: 0.1263\n",
      "  bc_avg_overall_fc2: 0.0108\n",
      "Task [6, 7] - Epoch 3/5: Loss = 0.3515\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 158.7744\n",
      "  erank_fc2: 56.4290\n",
      "  avg_contrib_fc1: 1.6226\n",
      "  avg_overall_fc1: 0.0577\n",
      "  bc_avg_contrib_fc1: 8.9106\n",
      "  bc_avg_overall_fc1: 0.3168\n",
      "  avg_contrib_fc2: 0.0225\n",
      "  avg_overall_fc2: 0.0019\n",
      "  bc_avg_contrib_fc2: 0.1233\n",
      "  bc_avg_overall_fc2: 0.0105\n",
      "Task [6, 7] - Epoch 4/5: Loss = 0.3029\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 165.2156\n",
      "  erank_fc2: 68.4960\n",
      "  avg_contrib_fc1: 1.6458\n",
      "  avg_overall_fc1: 0.0584\n",
      "  bc_avg_contrib_fc1: 8.6499\n",
      "  bc_avg_overall_fc1: 0.3070\n",
      "  avg_contrib_fc2: 0.0229\n",
      "  avg_overall_fc2: 0.0019\n",
      "  bc_avg_contrib_fc2: 0.1204\n",
      "  bc_avg_overall_fc2: 0.0102\n",
      "Task [6, 7] - Epoch 5/5: Loss = 0.2664\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 170.2339\n",
      "  erank_fc2: 75.4395\n",
      "  avg_contrib_fc1: 1.6684\n",
      "  avg_overall_fc1: 0.0591\n",
      "  bc_avg_contrib_fc1: 8.4108\n",
      "  bc_avg_overall_fc1: 0.2981\n",
      "  avg_contrib_fc2: 0.0234\n",
      "  avg_overall_fc2: 0.0020\n",
      "  bc_avg_contrib_fc2: 0.1178\n",
      "  bc_avg_overall_fc2: 0.0100\n",
      "\n",
      "=== Training on Task (classes [8, 9]) ===\n",
      "Task [8, 9] - Epoch 1/5: Loss = 1.2372\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 161.7153\n",
      "  erank_fc2: 20.2816\n",
      "  avg_contrib_fc1: 1.6960\n",
      "  avg_overall_fc1: 0.0600\n",
      "  bc_avg_contrib_fc1: 8.2175\n",
      "  bc_avg_overall_fc1: 0.2907\n",
      "  avg_contrib_fc2: 0.0243\n",
      "  avg_overall_fc2: 0.0020\n",
      "  bc_avg_contrib_fc2: 0.1177\n",
      "  bc_avg_overall_fc2: 0.0098\n",
      "Task [8, 9] - Epoch 2/5: Loss = 0.4475\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 175.4052\n",
      "  erank_fc2: 39.5838\n",
      "  avg_contrib_fc1: 1.7189\n",
      "  avg_overall_fc1: 0.0607\n",
      "  bc_avg_contrib_fc1: 8.0200\n",
      "  bc_avg_overall_fc1: 0.2833\n",
      "  avg_contrib_fc2: 0.0248\n",
      "  avg_overall_fc2: 0.0020\n",
      "  bc_avg_contrib_fc2: 0.1159\n",
      "  bc_avg_overall_fc2: 0.0095\n",
      "Task [8, 9] - Epoch 3/5: Loss = 0.3482\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 181.9420\n",
      "  erank_fc2: 45.5524\n",
      "  avg_contrib_fc1: 1.7406\n",
      "  avg_overall_fc1: 0.0614\n",
      "  bc_avg_contrib_fc1: 7.8343\n",
      "  bc_avg_overall_fc1: 0.2763\n",
      "  avg_contrib_fc2: 0.0253\n",
      "  avg_overall_fc2: 0.0021\n",
      "  bc_avg_contrib_fc2: 0.1141\n",
      "  bc_avg_overall_fc2: 0.0093\n",
      "Task [8, 9] - Epoch 4/5: Loss = 0.3134\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 187.9205\n",
      "  erank_fc2: 51.4539\n",
      "  avg_contrib_fc1: 1.7611\n",
      "  avg_overall_fc1: 0.0620\n",
      "  bc_avg_contrib_fc1: 7.6584\n",
      "  bc_avg_overall_fc1: 0.2697\n",
      "  avg_contrib_fc2: 0.0258\n",
      "  avg_overall_fc2: 0.0021\n",
      "  bc_avg_contrib_fc2: 0.1122\n",
      "  bc_avg_overall_fc2: 0.0091\n",
      "Task [8, 9] - Epoch 5/5: Loss = 0.2817\n",
      "Metrics after epoch:\n",
      "  erank_fc1: 193.5374\n",
      "  erank_fc2: 54.9395\n",
      "  avg_contrib_fc1: 1.7807\n",
      "  avg_overall_fc1: 0.0626\n",
      "  bc_avg_contrib_fc1: 7.4929\n",
      "  bc_avg_overall_fc1: 0.2636\n",
      "  avg_contrib_fc2: 0.0263\n",
      "  avg_overall_fc2: 0.0021\n",
      "  bc_avg_contrib_fc2: 0.1105\n",
      "  bc_avg_overall_fc2: 0.0089\n",
      "\n",
      "Test Accuracy of Continual Learning MLP: 16.99%\n",
      "\n",
      "=== Joint Training Experiment (Train on entire CIFAR10) ===\n",
      "Joint Training - Epoch 1/25: Loss = 1.7707\n",
      "Joint Training - Epoch 2/25: Loss = 1.4908\n",
      "Joint Training - Epoch 3/25: Loss = 1.3706\n",
      "Joint Training - Epoch 4/25: Loss = 1.2802\n",
      "Joint Training - Epoch 5/25: Loss = 1.2039\n",
      "Joint Training - Epoch 6/25: Loss = 1.1334\n",
      "Joint Training - Epoch 7/25: Loss = 1.0699\n",
      "Joint Training - Epoch 8/25: Loss = 1.0095\n",
      "Joint Training - Epoch 9/25: Loss = 0.9447\n",
      "Joint Training - Epoch 10/25: Loss = 0.8851\n",
      "Joint Training - Epoch 11/25: Loss = 0.8300\n",
      "Joint Training - Epoch 12/25: Loss = 0.7688\n",
      "Joint Training - Epoch 13/25: Loss = 0.7126\n",
      "Joint Training - Epoch 14/25: Loss = 0.6589\n",
      "Joint Training - Epoch 15/25: Loss = 0.6036\n",
      "Joint Training - Epoch 16/25: Loss = 0.5513\n",
      "Joint Training - Epoch 17/25: Loss = 0.4960\n",
      "Joint Training - Epoch 18/25: Loss = 0.4550\n",
      "Joint Training - Epoch 19/25: Loss = 0.4146\n",
      "Joint Training - Epoch 20/25: Loss = 0.3596\n",
      "Joint Training - Epoch 21/25: Loss = 0.3246\n",
      "Joint Training - Epoch 22/25: Loss = 0.2953\n",
      "Joint Training - Epoch 23/25: Loss = 0.2638\n",
      "Joint Training - Epoch 24/25: Loss = 0.2285\n",
      "Joint Training - Epoch 25/25: Loss = 0.2138\n",
      "\n",
      "Test Accuracy of Joint Training MLP: 55.55%\n",
      "\n",
      "=== Linear Model Experiment (Train on entire CIFAR10) ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 314\u001b[0m\n\u001b[1;32m    312\u001b[0m joint_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epochs_joint):\n\u001b[0;32m--> 314\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Model - Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_epochs_joint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    316\u001b[0m acc_linear \u001b[38;5;241m=\u001b[39m evaluate(linear_model, test_loader, device)\n",
      "Cell \u001b[0;32mIn[2], line 211\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m    209\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    210\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 211\u001b[0m outputs, _, _ \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    212\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    213\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "\n",
    "# Transform: convert to tensor and normalize.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Download CIFAR-10 training and test datasets.\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "# Helper function: Given a dataset and a list of target classes, return a Subset.\n",
    "def get_subset_by_classes(dataset, class_list):\n",
    "    indices = [i for i, (img, label) in enumerate(dataset) if label in class_list]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Define our 5 tasks: each task is a pair of classes.\n",
    "tasks = [\n",
    "    [0, 1],  # airplane, automobile\n",
    "    [2, 3],  # bird, cat\n",
    "    [4, 5],  # deer, dog\n",
    "    [6, 7],  # frog, horse\n",
    "    [8, 9]   # ship, truck\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define the MLP and Linear Model\n",
    "# -------------------------------\n",
    "\n",
    "# MLP that returns both output and hidden layer activations\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=3*32*32, hidden_size=512, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input: [batch, 3,32,32] -> [batch, 3072]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h2 = self.relu(self.fc2(h1))\n",
    "        out = self.fc3(h2)\n",
    "        return out, h1, h2  # returning activations for layers fc1 and fc2\n",
    "\n",
    "# A simple linear model (single linear layer)\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size=3*32*32, num_classes=10):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Utility Functions for Continual Metrics\n",
    "# -------------------------------\n",
    "\n",
    "# Compute effective rank of a representation (assumes activations is 2D: [N, D])\n",
    "def compute_effective_rank(activations):\n",
    "    # activations: [N, D]\n",
    "    # Use torch.svd (or torch.linalg.svd in recent versions)\n",
    "    try:\n",
    "        u, s, vh = torch.svd(activations)\n",
    "    except RuntimeError:\n",
    "        # Fall back to torch.linalg.svd if necessary\n",
    "        s = torch.linalg.svdvals(activations)\n",
    "    s_sum = torch.sum(s) + 1e-8\n",
    "    p = s / s_sum\n",
    "    erank = torch.exp(-torch.sum(p * torch.log(p + 1e-8)))\n",
    "    return erank.item()\n",
    "\n",
    "# Compute contribution utility for a layer.\n",
    "# activations: [N, D] for the given layer.\n",
    "# next_weight: weight matrix of the next layer, shape [out_dim, D].\n",
    "def compute_contrib_utility(activations, next_weight):\n",
    "    mean_abs = torch.mean(torch.abs(activations), dim=0)  # [D]\n",
    "    sum_out = torch.sum(torch.abs(next_weight), dim=0)      # [D]\n",
    "    return mean_abs * sum_out  # [D]\n",
    "\n",
    "# Compute adaptation utility for a layer given its incoming weight matrix.\n",
    "# weight_in: shape [D, in_features]\n",
    "def compute_adaptation_utility(weight_in):\n",
    "    sum_in = torch.sum(torch.abs(weight_in), dim=1)  # [D]\n",
    "    return 1.0 / (sum_in + 1e-8)\n",
    "\n",
    "# Overall utility: here defined as product of contribution and adaptation utilities.\n",
    "def compute_overall_utility(contrib, adaptation):\n",
    "    return contrib * adaptation\n",
    "\n",
    "# Exponential moving average update.\n",
    "def update_running_avg(old, current, eta):\n",
    "    if old is None:\n",
    "        return current\n",
    "    else:\n",
    "        return (1 - eta) * current + eta * old\n",
    "\n",
    "# Bias-correct the running average given the age (number of updates).\n",
    "def bias_corrected(running_avg, age, eta):\n",
    "    # age is assumed to be an integer or a torch scalar.\n",
    "    denom = 1 - eta ** (age + 1)\n",
    "    return running_avg / (denom + 1e-8)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Metric Measurement Routine\n",
    "# -------------------------------\n",
    "\n",
    "def measure_metrics(model, dataloader, device, eta, layer_names, running_avgs, ages):\n",
    "    \"\"\"\n",
    "    For each layer in layer_names (e.g., ['fc1','fc2']), this function:\n",
    "     - Collects activations from the model (by running through dataloader)\n",
    "     - Computes effective rank of the activations.\n",
    "     - Computes contribution utility using the next layer's weights.\n",
    "     - Computes adaptation utility from the layer's incoming weights.\n",
    "     - Computes overall utility = contrib * adaptation.\n",
    "     - Updates a running average for contribution and overall utilities using exponential smoothing.\n",
    "     - Increments the \"age\" (number of epochs seen).\n",
    "     - Computes bias-corrected running average utilities.\n",
    "     \n",
    "    running_avgs is a dict with keys: 'contrib' and 'overall', each mapping layer name -> tensor of shape [D] (or None initially).\n",
    "    ages is a dict mapping layer name -> age (integer).\n",
    "    \n",
    "    Returns a dict of metrics and updated running_avgs and ages.\n",
    "    \"\"\"\n",
    "    # We will aggregate activations for each layer over the dataloader.\n",
    "    activations = {ln: [] for ln in layer_names}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            out, h1, h2 = model(images)\n",
    "            # Save activations for each layer:\n",
    "            activations['fc1'].append(h1.cpu())\n",
    "            activations['fc2'].append(h2.cpu())\n",
    "    # Concatenate activations along the batch dimension.\n",
    "    for ln in layer_names:\n",
    "        activations[ln] = torch.cat(activations[ln], dim=0)  # shape: [N, D]\n",
    "    \n",
    "    metrics = {}\n",
    "    # Effective rank of each layer's representation.\n",
    "    for ln in layer_names:\n",
    "        er = compute_effective_rank(activations[ln])\n",
    "        metrics[f'erank_{ln}'] = er\n",
    "\n",
    "    # For contribution utility we need the weight matrices of the next layer.\n",
    "    # For fc1, next layer is fc2; for fc2, next layer is fc3.\n",
    "    with torch.no_grad():\n",
    "        # Assume model has attributes fc1, fc2, fc3.\n",
    "        # Contribution utility:\n",
    "        contrib_fc1 = compute_contrib_utility(activations['fc1'], model.fc2.weight.data.cpu())\n",
    "        contrib_fc2 = compute_contrib_utility(activations['fc2'], model.fc3.weight.data.cpu())\n",
    "        # Adaptation utility:\n",
    "        # For fc1, incoming weights: model.fc1.weight, shape [hidden, input]\n",
    "        adapt_fc1 = compute_adaptation_utility(model.fc1.weight.data.cpu())\n",
    "        # For fc2, incoming weights: model.fc2.weight, shape [hidden, hidden]\n",
    "        adapt_fc2 = compute_adaptation_utility(model.fc2.weight.data.cpu())\n",
    "        # Overall utility:\n",
    "        overall_fc1 = compute_overall_utility(contrib_fc1, adapt_fc1)\n",
    "        overall_fc2 = compute_overall_utility(contrib_fc2, adapt_fc2)\n",
    "        \n",
    "    # Update running averages and ages for each layer.\n",
    "    for ln, current_contrib in zip(layer_names, [contrib_fc1, contrib_fc2]):\n",
    "        # running average for contribution:\n",
    "        if running_avgs['contrib'].get(ln) is None:\n",
    "            running_avgs['contrib'][ln] = current_contrib.clone()\n",
    "        else:\n",
    "            running_avgs['contrib'][ln] = update_running_avg(running_avgs['contrib'][ln], current_contrib, eta)\n",
    "        # running average for overall:\n",
    "        current_overall = overall_fc1 if ln=='fc1' else overall_fc2\n",
    "        if running_avgs['overall'].get(ln) is None:\n",
    "            running_avgs['overall'][ln] = current_overall.clone()\n",
    "        else:\n",
    "            running_avgs['overall'][ln] = update_running_avg(running_avgs['overall'][ln], current_overall, eta)\n",
    "        # Increase age\n",
    "        ages[ln] = ages.get(ln, 0) + 1\n",
    "        # Bias-corrected running averages:\n",
    "        bc_contrib = bias_corrected(running_avgs['contrib'][ln], ages[ln], eta)\n",
    "        bc_overall = bias_corrected(running_avgs['overall'][ln], ages[ln], eta)\n",
    "        metrics[f'avg_contrib_{ln}'] = torch.mean(running_avgs['contrib'][ln]).item()\n",
    "        metrics[f'avg_overall_{ln}'] = torch.mean(running_avgs['overall'][ln]).item()\n",
    "        metrics[f'bc_avg_contrib_{ln}'] = torch.mean(bc_contrib).item()\n",
    "        metrics[f'bc_avg_overall_{ln}'] = torch.mean(bc_overall).item()\n",
    "    return metrics, running_avgs, ages\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training and Evaluation Functions (Same as before)\n",
    "# -------------------------------\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, dataloader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs, _, _ = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Continual Learning Training with Metrics Logging\n",
    "# -------------------------------\n",
    "\n",
    "def continual_training(model, tasks, train_dataset, eval_loader, epochs_per_task, batch_size, device, eta=0.99):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # We will track metrics for layers 'fc1' and 'fc2'\n",
    "    layer_names = ['fc1', 'fc2']\n",
    "    # Dictionaries to store running averages and ages per layer.\n",
    "    running_avgs = {'contrib': {}, 'overall': {}}\n",
    "    ages = {}\n",
    "    \n",
    "    # Before training, measure initial metrics.\n",
    "    print(\"=== Before Training: Metrics ===\")\n",
    "    metrics, running_avgs, ages = measure_metrics(model, eval_loader, device, eta, layer_names, running_avgs, ages)\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "        \n",
    "    # Now loop over tasks sequentially.\n",
    "    for task in tasks:\n",
    "        print(f\"\\n=== Training on Task (classes {task}) ===\")\n",
    "        task_subset = get_subset_by_classes(train_dataset, task)\n",
    "        task_loader = DataLoader(task_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        for epoch in range(epochs_per_task):\n",
    "            loss = train_epoch(model, optimizer, criterion, task_loader, device)\n",
    "            print(f\"Task {task} - Epoch {epoch+1}/{epochs_per_task}: Loss = {loss:.4f}\")\n",
    "            # At the end of each epoch, measure the metrics on the eval_loader.\n",
    "            metrics, running_avgs, ages = measure_metrics(model, eval_loader, device, eta, layer_names, running_avgs, ages)\n",
    "            print(\"Metrics after epoch:\")\n",
    "            for k, v in metrics.items():\n",
    "                print(f\"  {k}: {v:.4f}\")\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Joint Training (Train on Entire CIFAR10) -- without continual metrics\n",
    "# -------------------------------\n",
    "\n",
    "def joint_training(model, train_dataset, epochs, batch_size, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(model, optimizer, criterion, dataloader, device)\n",
    "        print(f\"Joint Training - Epoch {epoch+1}/{epochs}: Loss = {loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Main Experiment\n",
    "# -------------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    batch_size = 128\n",
    "    epochs_per_task = 5  # epochs per paired-task\n",
    "    num_tasks = len(tasks)\n",
    "    total_epochs_joint = epochs_per_task * num_tasks  # same total epochs for joint training\n",
    "    \n",
    "    # We also prepare an evaluation DataLoader (for metrics) using the test set.\n",
    "    eval_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(\"=== Continual Learning Experiment (Sequential Training on Task Pairs) ===\")\n",
    "    continual_model = MLP().to(device)\n",
    "    continual_model = continual_training(continual_model, tasks, train_dataset, eval_loader,\n",
    "                                          epochs_per_task, batch_size, device, eta=0.99)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    acc_continual = evaluate(continual_model, test_loader, device)\n",
    "    print(f\"\\nTest Accuracy of Continual Learning MLP: {acc_continual*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n=== Joint Training Experiment (Train on entire CIFAR10) ===\")\n",
    "    joint_model = MLP().to(device)\n",
    "    joint_model = joint_training(joint_model, train_dataset, total_epochs_joint, batch_size, device)\n",
    "    acc_joint = evaluate(joint_model, test_loader, device)\n",
    "    print(f\"\\nTest Accuracy of Joint Training MLP: {acc_joint*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n=== Linear Model Experiment (Train on entire CIFAR10) ===\")\n",
    "    linear_model = LinearModel().to(device)\n",
    "    linear_optimizer = optim.SGD(linear_model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    joint_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    for epoch in range(total_epochs_joint):\n",
    "        loss = train_epoch(linear_model, linear_optimizer, criterion, joint_loader, device)\n",
    "        print(f\"Linear Model - Epoch {epoch+1}/{total_epochs_joint}: Loss = {loss:.4f}\")\n",
    "    acc_linear = evaluate(linear_model, test_loader, device)\n",
    "    print(f\"\\nTest Accuracy of Linear Model: {acc_linear*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9478d678-0ecd-424a-9f9d-35bd29f90b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch 0 CC stats using threshold = 0.999\n",
      "layer layer_0 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_1 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_2 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_3 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_4 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_5 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_6 feature dim = 1000 # of connected components: 1000\n",
      "Epoch 1: Train Loss: 0.0000, Val Loss: 18.0068 | Effective Rank per layer: layer_0: 657.69, layer_1: 671.36, layer_2: 675.24, layer_3: 678.24, layer_4: 681.57, layer_5: 684.71, layer_6: 686.90\n",
      "epoch 1 CC stats using threshold = 0.999\n",
      "layer layer_0 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_1 feature dim = 1000 # of connected components: 939\n",
      "layer layer_2 feature dim = 1000 # of connected components: 263\n",
      "layer layer_3 feature dim = 1000 # of connected components: 39\n",
      "layer layer_4 feature dim = 1000 # of connected components: 12\n",
      "layer layer_5 feature dim = 1000 # of connected components: 1\n",
      "layer layer_6 feature dim = 1000 # of connected components: 1\n",
      "Epoch 2: Train Loss: 26.0700, Val Loss: 26.4546 | Effective Rank per layer: layer_0: 584.09, layer_1: 428.84, layer_2: 246.32, layer_3: 75.26, layer_4: 16.49, layer_5: 3.52, layer_6: 1.56\n",
      "epoch 2 CC stats using threshold = 0.999\n",
      "layer layer_0 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_1 feature dim = 1000 # of connected components: 966\n",
      "layer layer_2 feature dim = 1000 # of connected components: 197\n",
      "layer layer_3 feature dim = 1000 # of connected components: 29\n",
      "layer layer_4 feature dim = 1000 # of connected components: 14\n",
      "layer layer_5 feature dim = 1000 # of connected components: 1\n",
      "layer layer_6 feature dim = 1000 # of connected components: 1\n",
      "Epoch 3: Train Loss: 22.0228, Val Loss: 23.8273 | Effective Rank per layer: layer_0: 590.64, layer_1: 408.92, layer_2: 221.66, layer_3: 70.27, layer_4: 15.03, layer_5: 3.22, layer_6: 1.57\n",
      "epoch 3 CC stats using threshold = 0.999\n",
      "layer layer_0 feature dim = 1000 # of connected components: 1000\n",
      "layer layer_1 feature dim = 1000 # of connected components: 980\n",
      "layer layer_2 feature dim = 1000 # of connected components: 261\n",
      "layer layer_3 feature dim = 1000 # of connected components: 37\n",
      "layer layer_4 feature dim = 1000 # of connected components: 14\n",
      "layer layer_5 feature dim = 1000 # of connected components: 2\n",
      "layer layer_6 feature dim = 1000 # of connected components: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 164\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, act \u001b[38;5;129;01min\u001b[39;00m val_batch_activations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    163\u001b[0m     act_matrix \u001b[38;5;241m=\u001b[39m act\u001b[38;5;241m.\u001b[39mview(act\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m     erank_dict[layer_name] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_effective_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Report training loss, validation loss, and effective rank per layer for this epoch\u001b[39;00m\n\u001b[1;32m    167\u001b[0m erank_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m erank_dict\u001b[38;5;241m.\u001b[39mitems()])\n",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m, in \u001b[0;36mcompute_effective_rank\u001b[0;34m(activation_matrix, eps)\u001b[0m\n\u001b[1;32m     42\u001b[0m act \u001b[38;5;241m=\u001b[39m activation_matrix\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Compute SVD\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m U, S, V \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m S_sum \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m eps  \u001b[38;5;66;03m# Avoid division by zero\u001b[39;00m\n\u001b[1;32m     46\u001b[0m p \u001b[38;5;241m=\u001b[39m S \u001b[38;5;241m/\u001b[39m S_sum         \u001b[38;5;66;03m# Normalized singular values\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a789e-3205-4dc4-ae79-a00d2f8f21f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4bf0b2b-1334-4bdc-a308-57b3175e4a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetWithHooks(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8943c5-b27e-44f7-83b7-2c160af3467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.8462 Acc: 0.3340\n",
      "val Loss: 1.5380 Acc: 0.4425\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  633  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  639  rank(A) =  640\n",
      "key =  layer4  CC =  539  rank(A) =  640\n",
      "key =  avgpool  CC =  58  rank(A) =  512\n",
      "key =  logits  CC =  8  rank(A) =  10\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.3833 Acc: 0.4971\n",
      "val Loss: 1.2382 Acc: 0.5549\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  640  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  640  rank(A) =  640\n",
      "key =  layer4  CC =  629  rank(A) =  640\n",
      "key =  avgpool  CC =  186  rank(A) =  512\n",
      "key =  logits  CC =  22  rank(A) =  10\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.0947 Acc: 0.6105\n",
      "val Loss: 1.1704 Acc: 0.6003\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  640  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  637  rank(A) =  640\n",
      "key =  layer4  CC =  640  rank(A) =  640\n",
      "key =  avgpool  CC =  141  rank(A) =  512\n",
      "key =  logits  CC =  15  rank(A) =  10\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.9201 Acc: 0.6737\n",
      "val Loss: 0.8815 Acc: 0.6926\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  640  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  640  rank(A) =  640\n",
      "key =  layer4  CC =  639  rank(A) =  640\n",
      "key =  avgpool  CC =  264  rank(A) =  512\n",
      "key =  logits  CC =  28  rank(A) =  10\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.7841 Acc: 0.7267\n",
      "val Loss: 0.9918 Acc: 0.6744\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  640  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  640  rank(A) =  640\n",
      "key =  layer4  CC =  636  rank(A) =  640\n",
      "key =  avgpool  CC =  215  rank(A) =  512\n",
      "key =  logits  CC =  20  rank(A) =  10\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.6681 Acc: 0.7670\n",
      "val Loss: 0.7134 Acc: 0.7543\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  640  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  640  rank(A) =  640\n",
      "key =  layer4  CC =  638  rank(A) =  640\n",
      "key =  avgpool  CC =  250  rank(A) =  512\n",
      "key =  logits  CC =  20  rank(A) =  10\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.5928 Acc: 0.7943\n",
      "val Loss: 0.9427 Acc: 0.6793\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  632  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  640  rank(A) =  640\n",
      "key =  layer4  CC =  636  rank(A) =  640\n",
      "key =  avgpool  CC =  214  rank(A) =  512\n",
      "key =  logits  CC =  19  rank(A) =  10\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.5523 Acc: 0.8094\n",
      "val Loss: 0.6260 Acc: 0.7879\n",
      "report CC stats for phase val\n",
      "key =  initial_relu  CC =  630  rank(A) =  640\n",
      "key =  layer1  CC =  640  rank(A) =  640\n",
      "key =  layer2  CC =  640  rank(A) =  640\n",
      "key =  layer3  CC =  640  rank(A) =  640\n",
      "key =  layer4  CC =  629  rank(A) =  640\n",
      "key =  avgpool  CC =  223  rank(A) =  512\n",
      "key =  logits  CC =  19  rank(A) =  10\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3666c0-01d8-4ea4-847f-78937f11d78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/100\n",
      "Train Loss: 1.8716 | Train Acc: 28.60%\n",
      "Val Loss: 1.7739 | Val Acc: 33.96%\n",
      "Epoch: 2/100\n",
      "Train Loss: 1.6630 | Train Acc: 37.41%\n",
      "Val Loss: 1.5279 | Val Acc: 43.72%\n",
      "Epoch: 3/100\n",
      "Train Loss: 1.5240 | Train Acc: 43.63%\n",
      "Val Loss: 1.4582 | Val Acc: 47.39%\n",
      "Epoch: 4/100\n",
      "Train Loss: 1.4439 | Train Acc: 47.15%\n",
      "Val Loss: 1.4285 | Val Acc: 48.79%\n",
      "Epoch: 5/100\n",
      "Train Loss: 1.3721 | Train Acc: 50.10%\n",
      "Val Loss: 1.3193 | Val Acc: 52.65%\n",
      "Epoch: 6/100\n",
      "Train Loss: 1.3198 | Train Acc: 52.09%\n",
      "Val Loss: 1.2573 | Val Acc: 54.83%\n",
      "Epoch: 7/100\n",
      "Train Loss: 1.2773 | Train Acc: 53.61%\n",
      "Val Loss: 1.1865 | Val Acc: 57.50%\n",
      "Epoch: 8/100\n",
      "Train Loss: 1.2440 | Train Acc: 54.96%\n",
      "Val Loss: 1.1456 | Val Acc: 58.21%\n",
      "Epoch: 9/100\n",
      "Train Loss: 1.2049 | Train Acc: 56.28%\n",
      "Val Loss: 1.1430 | Val Acc: 59.03%\n",
      "Epoch: 10/100\n",
      "Train Loss: 1.1715 | Train Acc: 57.47%\n",
      "Val Loss: 1.1197 | Val Acc: 59.52%\n",
      "Epoch: 11/100\n",
      "Train Loss: 1.1337 | Train Acc: 59.10%\n",
      "Val Loss: 1.0618 | Val Acc: 61.79%\n",
      "Epoch: 12/100\n",
      "Train Loss: 1.1064 | Train Acc: 60.22%\n",
      "Val Loss: 1.0299 | Val Acc: 62.79%\n",
      "Epoch: 13/100\n",
      "Train Loss: 1.0673 | Train Acc: 61.59%\n",
      "Val Loss: 1.0016 | Val Acc: 64.08%\n",
      "Epoch: 14/100\n",
      "Train Loss: 1.0391 | Train Acc: 62.91%\n",
      "Val Loss: 0.9934 | Val Acc: 64.24%\n",
      "Epoch: 15/100\n",
      "Train Loss: 1.0060 | Train Acc: 64.15%\n",
      "Val Loss: 0.9742 | Val Acc: 65.07%\n",
      "Epoch: 16/100\n",
      "Train Loss: 0.9695 | Train Acc: 65.34%\n",
      "Val Loss: 0.8964 | Val Acc: 67.74%\n",
      "Epoch: 17/100\n",
      "Train Loss: 0.9486 | Train Acc: 66.17%\n",
      "Val Loss: 0.8822 | Val Acc: 68.44%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 235\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 220\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 220\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, testloader, criterion, device)\n\u001b[1;32m    222\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[1], line 151\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    148\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    149\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 151\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    153\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151b31b4-fd6c-4e09-8dae-74d3c5a1be0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b624a8-74b0-4b77-b1ca-11224046418c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
