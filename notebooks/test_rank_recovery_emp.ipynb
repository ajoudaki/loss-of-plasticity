{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Configuration: MLP NoNorm ---\n",
      "Using fixed val batch of size 512 for rank eval.\n",
      "Logging ranks for Epoch 0 (Initialization) for MLP NoNorm...\n",
      "Epoch 0 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:32.5 | H1_ReLU:59.1 | H2_Linear:47.5 | H2_ReLU:84.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:14.7 | H1_ReLU:34.3 | H2_Linear:18.0 | H2_ReLU:50.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:19.0 | H1_ReLU:43.9 | H2_Linear:21.1 | H2_ReLU:65.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:21.7 | H1_ReLU:49.6 | H2_Linear:23.1 | H2_ReLU:75.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:24.6 | H1_ReLU:54.3 | H2_Linear:24.3 | H2_ReLU:85.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:26.4 | H1_ReLU:57.4 | H2_Linear:24.7 | H2_ReLU:91.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:28.3 | H1_ReLU:61.0 | H2_Linear:26.3 | H2_ReLU:98.1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:29.2 | H1_ReLU:61.8 | H2_Linear:26.0 | H2_ReLU:102.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:30.5 | H1_ReLU:63.7 | H2_Linear:27.3 | H2_ReLU:108.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:31.4 | H1_ReLU:65.2 | H2_Linear:26.9 | H2_ReLU:111.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:32.6 | H1_ReLU:67.1 | H2_Linear:28.2 | H2_ReLU:113.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:33.5 | H1_ReLU:68.4 | H2_Linear:28.9 | H2_ReLU:115.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:34.0 | H1_ReLU:68.9 | H2_Linear:28.2 | H2_ReLU:117.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:34.7 | H1_ReLU:69.8 | H2_Linear:29.2 | H2_ReLU:118.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:35.2 | H1_ReLU:70.7 | H2_Linear:29.3 | H2_ReLU:119.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:35.8 | H1_ReLU:71.2 | H2_Linear:30.0 | H2_ReLU:121.3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:36.1 | H1_ReLU:72.2 | H2_Linear:29.7 | H2_ReLU:122.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:36.0 | H1_ReLU:70.9 | H2_Linear:29.4 | H2_ReLU:122.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:36.3 | H1_ReLU:72.4 | H2_Linear:30.0 | H2_ReLU:121.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:37.2 | H1_ReLU:73.1 | H2_Linear:30.1 | H2_ReLU:122.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:37.1 | H1_ReLU:73.0 | H2_Linear:30.2 | H2_ReLU:123.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:36.8 | H1_ReLU:72.5 | H2_Linear:30.0 | H2_ReLU:123.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:37.0 | H1_ReLU:72.5 | H2_Linear:29.9 | H2_ReLU:123.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:37.8 | H1_ReLU:74.1 | H2_Linear:30.8 | H2_ReLU:124.3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:37.7 | H1_ReLU:73.5 | H2_Linear:30.6 | H2_ReLU:124.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:37.6 | H1_ReLU:73.5 | H2_Linear:30.4 | H2_ReLU:123.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.0 | H1_ReLU:74.0 | H2_Linear:30.9 | H2_ReLU:123.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.6 | H1_ReLU:75.1 | H2_Linear:31.2 | H2_ReLU:125.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.2 | H1_ReLU:74.5 | H2_Linear:30.6 | H2_ReLU:124.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.4 | H1_ReLU:74.9 | H2_Linear:30.8 | H2_ReLU:125.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.1 | H1_ReLU:74.3 | H2_Linear:30.8 | H2_ReLU:126.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.3 | H1_ReLU:74.4 | H2_Linear:30.8 | H2_ReLU:123.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.5 | H1_ReLU:74.7 | H2_Linear:30.4 | H2_ReLU:126.1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.7 | H1_ReLU:74.8 | H2_Linear:30.4 | H2_ReLU:126.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.4 | H1_ReLU:74.5 | H2_Linear:30.7 | H2_ReLU:125.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.1 | H1_ReLU:75.8 | H2_Linear:31.4 | H2_ReLU:127.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.0 | H1_ReLU:75.3 | H2_Linear:31.3 | H2_ReLU:126.1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.8 | H1_ReLU:74.9 | H2_Linear:30.8 | H2_ReLU:126.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.2 | H1_ReLU:75.8 | H2_Linear:30.9 | H2_ReLU:126.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.0 | H1_ReLU:75.1 | H2_Linear:30.9 | H2_ReLU:126.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.8 | H1_ReLU:75.1 | H2_Linear:31.2 | H2_ReLU:125.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.2 | H1_ReLU:76.2 | H2_Linear:31.5 | H2_ReLU:128.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.3 | H1_ReLU:75.8 | H2_Linear:30.6 | H2_ReLU:126.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.2 | H1_ReLU:76.1 | H2_Linear:31.3 | H2_ReLU:128.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.8 | H1_ReLU:75.1 | H2_Linear:30.7 | H2_ReLU:128.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.3 | H1_ReLU:75.9 | H2_Linear:31.3 | H2_ReLU:126.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.1 | H1_ReLU:75.5 | H2_Linear:30.9 | H2_ReLU:128.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.1 | H1_ReLU:75.4 | H2_Linear:30.5 | H2_ReLU:126.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:38.9 | H1_ReLU:75.1 | H2_Linear:30.5 | H2_ReLU:126.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.1 | H1_ReLU:75.5 | H2_Linear:31.2 | H2_ReLU:129.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 [MLP NoNorm] Ranks: Input:34.7 | H1_Linear:39.8 | H1_ReLU:76.4 | H2_Linear:31.4 | H2_ReLU:128.9 ...\n",
      "Finished training for MLP NoNorm\n",
      "\n",
      "--- Running Configuration: MLP BatchNorm ---\n",
      "Using fixed val batch of size 512 for rank eval.\n",
      "Logging ranks for Epoch 0 (Initialization) for MLP BatchNorm...\n",
      "Epoch 0 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:34.7 | H1_BatchNorm:34.7 | H1_ReLU:63.5 | H2_Linear:43.3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:12.1 | H1_BatchNorm:12.1 | H1_ReLU:28.7 | H2_Linear:19.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:15.8 | H1_BatchNorm:15.8 | H1_ReLU:36.8 | H2_Linear:23.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:19.0 | H1_BatchNorm:19.0 | H1_ReLU:43.6 | H2_Linear:26.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:20.7 | H1_BatchNorm:20.7 | H1_ReLU:47.6 | H2_Linear:27.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:22.8 | H1_BatchNorm:22.8 | H1_ReLU:51.2 | H2_Linear:29.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:24.6 | H1_BatchNorm:24.6 | H1_ReLU:55.6 | H2_Linear:30.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:26.9 | H1_BatchNorm:26.9 | H1_ReLU:60.7 | H2_Linear:33.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:27.6 | H1_BatchNorm:27.6 | H1_ReLU:62.2 | H2_Linear:34.3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:29.3 | H1_BatchNorm:29.3 | H1_ReLU:65.1 | H2_Linear:35.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:30.4 | H1_BatchNorm:30.4 | H1_ReLU:67.1 | H2_Linear:36.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:31.8 | H1_BatchNorm:31.8 | H1_ReLU:70.5 | H2_Linear:38.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:32.2 | H1_BatchNorm:32.2 | H1_ReLU:71.0 | H2_Linear:38.9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:34.0 | H1_BatchNorm:34.0 | H1_ReLU:74.0 | H2_Linear:40.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:33.8 | H1_BatchNorm:33.8 | H1_ReLU:74.0 | H2_Linear:40.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:35.0 | H1_BatchNorm:35.0 | H1_ReLU:76.1 | H2_Linear:42.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:35.5 | H1_BatchNorm:35.5 | H1_ReLU:77.5 | H2_Linear:43.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:35.4 | H1_BatchNorm:35.4 | H1_ReLU:77.1 | H2_Linear:42.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:35.6 | H1_BatchNorm:35.6 | H1_ReLU:77.8 | H2_Linear:43.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:36.6 | H1_BatchNorm:36.6 | H1_ReLU:79.1 | H2_Linear:44.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:37.4 | H1_BatchNorm:37.4 | H1_ReLU:80.7 | H2_Linear:45.3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:36.9 | H1_BatchNorm:36.9 | H1_ReLU:80.0 | H2_Linear:44.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.2 | H1_BatchNorm:38.2 | H1_ReLU:82.1 | H2_Linear:46.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:37.7 | H1_BatchNorm:37.7 | H1_ReLU:81.4 | H2_Linear:45.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:37.6 | H1_BatchNorm:37.6 | H1_ReLU:81.5 | H2_Linear:45.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.1 | H1_BatchNorm:38.1 | H1_ReLU:82.0 | H2_Linear:46.3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.7 | H1_BatchNorm:38.7 | H1_ReLU:82.7 | H2_Linear:46.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.4 | H1_BatchNorm:38.4 | H1_ReLU:82.8 | H2_Linear:46.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.2 | H1_BatchNorm:38.2 | H1_ReLU:82.6 | H2_Linear:46.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.0 | H1_BatchNorm:39.0 | H1_ReLU:84.1 | H2_Linear:47.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.2 | H1_BatchNorm:39.2 | H1_ReLU:84.0 | H2_Linear:47.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.4 | H1_BatchNorm:39.4 | H1_ReLU:84.6 | H2_Linear:47.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.9 | H1_BatchNorm:38.9 | H1_ReLU:84.0 | H2_Linear:47.1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:38.8 | H1_BatchNorm:38.8 | H1_ReLU:83.8 | H2_Linear:47.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.3 | H1_BatchNorm:39.3 | H1_ReLU:84.2 | H2_Linear:47.7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.5 | H1_BatchNorm:39.5 | H1_ReLU:84.2 | H2_Linear:47.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:40.2 | H1_BatchNorm:40.2 | H1_ReLU:85.6 | H2_Linear:48.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.9 | H1_BatchNorm:39.9 | H1_ReLU:85.2 | H2_Linear:48.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.7 | H1_BatchNorm:39.7 | H1_ReLU:85.0 | H2_Linear:47.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:40.2 | H1_BatchNorm:40.2 | H1_ReLU:85.6 | H2_Linear:47.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:40.0 | H1_BatchNorm:40.0 | H1_ReLU:85.8 | H2_Linear:48.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:39.9 | H1_BatchNorm:39.9 | H1_ReLU:86.0 | H2_Linear:48.8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:40.3 | H1_BatchNorm:40.3 | H1_ReLU:86.6 | H2_Linear:48.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 [MLP BatchNorm] Ranks: Input:34.7 | H1_Linear:40.3 | H1_BatchNorm:40.3 | H1_ReLU:86.1 | H2_Linear:48.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D # For custom legends if needed later\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Matplotlib Styling (Optional) ---\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 13, # Slightly smaller for subplots\n",
    "    'axes.labelsize': 11,\n",
    "    'xtick.labelsize': 8, # Smaller for potentially many layer names\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 8,\n",
    "    'figure.titlesize': 15, # Main figure title\n",
    "    'lines.linewidth': 1.5,\n",
    "    'lines.markersize': 4\n",
    "})\n",
    "\n",
    "# --- 1. Helper Functions ---\n",
    "\n",
    "def compute_effective_rank(activations_batch):\n",
    "    if activations_batch.ndim == 1:\n",
    "        if activations_batch.shape[0] > 1: return 1.0\n",
    "        else: activations_batch = activations_batch.unsqueeze(0)\n",
    "    if activations_batch.shape[1] == 0: return 0.0\n",
    "    if activations_batch.shape[1] == 1: return 1.0\n",
    "    if activations_batch.shape[0] <= 1: return 1.0\n",
    "\n",
    "    std_devs = torch.std(activations_batch, dim=0)\n",
    "    valid_features_mask = std_devs > 1e-5\n",
    "    if valid_features_mask.sum() < 2: return float(valid_features_mask.sum().item())\n",
    "    activations_batch_filtered = activations_batch[:, valid_features_mask]\n",
    "\n",
    "    try:\n",
    "        if activations_batch_filtered.shape[0] <= 1 or activations_batch_filtered.shape[1] < 2:\n",
    "            return float(activations_batch_filtered.shape[1] > 0)\n",
    "        corr_matrix = torch.corrcoef(activations_batch_filtered.T)\n",
    "    except RuntimeError: return 1.0\n",
    "    if torch.isnan(corr_matrix).any(): corr_matrix = torch.nan_to_num(corr_matrix, nan=0.0)\n",
    "\n",
    "    s_unnormalized = torch.linalg.svdvals(corr_matrix)\n",
    "    sum_s = torch.sum(s_unnormalized)\n",
    "    if sum_s < 1e-12: return 0.0\n",
    "    s_norm_for_entropy = s_unnormalized / sum_s\n",
    "    s_norm_for_entropy = s_norm_for_entropy[s_norm_for_entropy > 1e-15]\n",
    "    if len(s_norm_for_entropy) == 0: return 0.0\n",
    "    entropy = -torch.sum(s_norm_for_entropy * torch.log(s_norm_for_entropy))\n",
    "    return torch.exp(entropy).item()\n",
    "\n",
    "def get_activation_fn_and_name(activation_name_str):\n",
    "    name = activation_name_str.lower()\n",
    "    if name == \"relu\": return nn.ReLU(), \"ReLU\"\n",
    "    elif name == \"tanh\": return nn.Tanh(), \"Tanh\"\n",
    "    elif name == \"sigmoid\": return nn.Sigmoid(), \"Sigmoid\"\n",
    "    elif name == \"gelu\": return nn.GELU(), \"GELU\"\n",
    "    elif name == \"identity\": return nn.Identity(), \"Identity\"\n",
    "    else: raise ValueError(f\"Unsupported activation: {activation_name_str}\")\n",
    "\n",
    "# --- 2. Model Definition ---\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, norm_type, activation_fn_instance, dropout_p, is_output_layer_block, block_idx):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.norm = None\n",
    "        self.act_fn_instance = activation_fn_instance # Store for naming\n",
    "        self.norm_type_str = norm_type # Store for naming\n",
    "        self.is_output_layer_block = is_output_layer_block\n",
    "        self.block_idx = block_idx # e.g., 0 for H1, 1 for H2...\n",
    "\n",
    "        layer_prefix = f\"H{block_idx + 1}\" if not is_output_layer_block else \"Output\"\n",
    "        self.layer_names = {\"linear\": f\"{layer_prefix}_Linear\"}\n",
    "\n",
    "\n",
    "        if not is_output_layer_block and norm_type:\n",
    "            if norm_type.lower() == \"batchnorm\":\n",
    "                self.norm = nn.BatchNorm1d(out_dim)\n",
    "                self.layer_names[\"norm\"] = f\"{layer_prefix}_BatchNorm\"\n",
    "            elif norm_type.lower() == \"layernorm\":\n",
    "                self.norm = nn.LayerNorm(out_dim)\n",
    "                self.layer_names[\"norm\"] = f\"{layer_prefix}_LayerNorm\"\n",
    "            elif norm_type.lower() != \"none\":\n",
    "                raise ValueError(f\"Unsupported norm_type: {norm_type}\")\n",
    "        \n",
    "        if not is_output_layer_block:\n",
    "            self.act = activation_fn_instance\n",
    "            act_name = self.act.__class__.__name__ if not isinstance(self.act, nn.modules.activation.Tanh) else \"Tanh\" # Tanh doesn't have a clean name sometimes\n",
    "            if isinstance(self.act, nn.Identity): act_name = \"Identity\" # Handle explicit Identity\n",
    "            self.layer_names[\"act\"] = f\"{layer_prefix}_{act_name}\"\n",
    "        else:\n",
    "            self.act = nn.Identity() # Output layer has no activation for logits\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p) if not is_output_layer_block and dropout_p > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, record_activations_in_block=False):\n",
    "        recorded_stages_in_block = [] # List of (name, tensor)\n",
    "\n",
    "        x_linear = self.linear(x)\n",
    "        if record_activations_in_block:\n",
    "            recorded_stages_in_block.append((self.layer_names[\"linear\"], x_linear.detach().cpu()))\n",
    "        \n",
    "        current_x = x_linear\n",
    "        if not self.is_output_layer_block:\n",
    "            if self.norm:\n",
    "                current_x = self.norm(current_x)\n",
    "                if record_activations_in_block:\n",
    "                    recorded_stages_in_block.append((self.layer_names[\"norm\"], current_x.detach().cpu()))\n",
    "            \n",
    "            current_x = self.act(current_x)\n",
    "            if record_activations_in_block:\n",
    "                recorded_stages_in_block.append((self.layer_names[\"act\"], current_x.detach().cpu()))\n",
    "            \n",
    "            output_for_next_layer = self.dropout(current_x)\n",
    "        else: # Output layer block\n",
    "            output_for_next_layer = current_x # This is the logits\n",
    "\n",
    "        if record_activations_in_block:\n",
    "            return output_for_next_layer, recorded_stages_in_block\n",
    "        else:\n",
    "            return output_for_next_layer, []\n",
    "\n",
    "\n",
    "class ConfigurableMLP(nn.Module):\n",
    "    def __init__(self, layer_dims, activation_name=\"relu\", norm_type=None, dropout_p=0.0):\n",
    "        super().__init__()\n",
    "        self.layer_dims = layer_dims\n",
    "        self.input_dim = layer_dims[0]\n",
    "        self.activation_name_str = activation_name # Store for reference\n",
    "        self.norm_type_str = norm_type\n",
    "        \n",
    "        act_fn_instance, _ = get_activation_fn_and_name(activation_name)\n",
    "        self.layer_stage_names = [\"Input\"] # Start with input\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(len(layer_dims) - 1):\n",
    "            is_final_block = (i == len(layer_dims) - 2)\n",
    "            block = MLPBlock(\n",
    "                layer_dims[i], layer_dims[i+1],\n",
    "                norm_type, act_fn_instance, dropout_p,\n",
    "                is_output_layer_block=is_final_block,\n",
    "                block_idx=i \n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            # Collect layer names from the block\n",
    "            self.layer_stage_names.append(block.layer_names[\"linear\"])\n",
    "            if \"norm\" in block.layer_names:\n",
    "                self.layer_stage_names.append(block.layer_names[\"norm\"])\n",
    "            if \"act\" in block.layer_names: # \"act\" only if not output block\n",
    "                 self.layer_stage_names.append(block.layer_names[\"act\"])\n",
    "            \n",
    "    def forward(self, x, record_activations=False):\n",
    "        x_flattened = x.view(x.size(0), -1)\n",
    "        if x_flattened.shape[1] != self.input_dim:\n",
    "            raise ValueError(f\"Input dim mismatch: {x_flattened.shape[1]} vs {self.input_dim}\")\n",
    "\n",
    "        all_recorded_stages = [] # List of (name, tensor)\n",
    "        current_features = x_flattened\n",
    "        \n",
    "        if record_activations:\n",
    "            all_recorded_stages.append((\"Input\", current_features.detach().cpu()))\n",
    "\n",
    "        for block in self.blocks:\n",
    "            current_features, block_recorded_activations = block(current_features, record_activations_in_block=record_activations)\n",
    "            if record_activations:\n",
    "                all_recorded_stages.extend(block_recorded_activations)\n",
    "        \n",
    "        final_model_output = current_features\n",
    "\n",
    "        if record_activations:\n",
    "            return final_model_output, all_recorded_stages\n",
    "        return final_model_output\n",
    "\n",
    "# --- 3. Data Handling ---\n",
    "def get_cifar10_dataloaders(batch_size=128, num_workers=2):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    try:\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) # Changed path\n",
    "    except Exception as e: print(f\"Error training set: {e}\"); raise\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "    try:\n",
    "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform) # Changed path\n",
    "    except Exception as e: print(f\"Error test set: {e}\"); raise\n",
    "    testloader = DataLoader(testset, batch_size=batch_size*2, shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "    return trainloader, testloader\n",
    "\n",
    "# --- 4. Training and Evaluation Loop with Rank Logging ---\n",
    "def _log_ranks_for_epoch(model, fixed_val_images, epoch_num, model_config_name, all_rank_data_list):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, recorded_stages = model(fixed_val_images, record_activations=True)\n",
    "        current_epoch_ranks_info = []\n",
    "        for stage_name, acts_batch in recorded_stages:\n",
    "            eff_rank = np.nan\n",
    "            if acts_batch.size(0) > 1 and acts_batch.ndim > 1 and acts_batch.shape[1] > 0:\n",
    "                eff_rank = compute_effective_rank(acts_batch)\n",
    "            \n",
    "            all_rank_data_list.append({\n",
    "                'model_config': model_config_name, 'epoch': epoch_num,\n",
    "                'layer_name': stage_name, 'eff_rank': eff_rank\n",
    "            })\n",
    "            current_epoch_ranks_info.append(f\"{stage_name}:{eff_rank:.1f}\" if not np.isnan(eff_rank) else f\"{stage_name}:NaN\")\n",
    "    \n",
    "    print(f\"Epoch {epoch_num} [{model_config_name}] Ranks: {' | '.join(current_epoch_ranks_info[:5])} ...\") # Print first few\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_with_rank_logging(\n",
    "    model_config_name, model, train_loader, val_loader, \n",
    "    optimizer, criterion, num_epochs, device, \n",
    "    log_rank_every_n_epochs=1, rank_eval_batch_size=256\n",
    "    ):\n",
    "    \n",
    "    all_rank_data = [] \n",
    "    fixed_val_images = None \n",
    "    try: # Prepare fixed validation batch\n",
    "        fixed_val_images_list = []\n",
    "        num_batches_for_rank = 1\n",
    "        if val_loader.batch_size and val_loader.batch_size > 0 :\n",
    "            num_batches_for_rank = max(1, rank_eval_batch_size // val_loader.batch_size)\n",
    "        elif rank_eval_batch_size > 0 :\n",
    "             print(f\"Warning: val_loader.batch_size is None/0. Will fetch {rank_eval_batch_size} samples.\")\n",
    "        else: raise ValueError(\"val_loader.batch_size is None/0, and rank_eval_batch_size not positive.\")\n",
    "\n",
    "        val_iter_for_rank = iter(val_loader)\n",
    "        current_fetched_samples = 0\n",
    "        while current_fetched_samples < rank_eval_batch_size:\n",
    "            try:\n",
    "                imgs, _ = next(val_iter_for_rank)\n",
    "                fixed_val_images_list.append(imgs)\n",
    "                current_fetched_samples += imgs.size(0)\n",
    "            except StopIteration: print(\"Warning: Val loader exhausted for rank batch.\"); break\n",
    "        if not fixed_val_images_list: raise ValueError(\"Val loader empty/too small for rank batch.\")\n",
    "        fixed_val_images_cat = torch.cat(fixed_val_images_list, dim=0)\n",
    "        if fixed_val_images_cat.size(0) > rank_eval_batch_size:\n",
    "            fixed_val_images_cat = fixed_val_images_cat[:rank_eval_batch_size]\n",
    "        if fixed_val_images_cat.size(0) == 0: raise ValueError(\"No images for fixed_val_images.\")\n",
    "        fixed_val_images = fixed_val_images_cat.to(device)\n",
    "        print(f\"Using fixed val batch of size {fixed_val_images.shape[0]} for rank eval.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not prepare fixed val batch: {e}. Falling back to train batch.\")\n",
    "        try:\n",
    "            fb_imgs, _ = next(iter(train_loader)) \n",
    "            if fb_imgs.size(0) > rank_eval_batch_size: fb_imgs = fb_imgs[:rank_eval_batch_size]\n",
    "            fixed_val_images = fb_imgs.to(device)\n",
    "        except Exception as fallback_e: print(f\"Fallback failed: {fallback_e}. No rank logging.\"); return pd.DataFrame(all_rank_data)\n",
    "\n",
    "    # --- Log Ranks at Epoch 0 (Initialization) ---\n",
    "    if fixed_val_images is not None and fixed_val_images.nelement() > 0:\n",
    "        print(f\"Logging ranks for Epoch 0 (Initialization) for {model_config_name}...\")\n",
    "        _log_ranks_for_epoch(model, fixed_val_images, 0, model_config_name, all_rank_data)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), \n",
    "                            desc=f\"Epoch {epoch+1}/{num_epochs} [{model_config_name}]\", leave=False)\n",
    "        for i, data in progress_bar:\n",
    "            inputs, labels = data; inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad(); outputs = model(inputs); loss = criterion(outputs, labels)\n",
    "            loss.backward(); optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 100 == 0: progress_bar.set_postfix({'loss': f'{running_loss / 100:.3f}'}); running_loss = 0.0\n",
    "        \n",
    "        if (epoch + 1) % log_rank_every_n_epochs == 0 and fixed_val_images is not None and fixed_val_images.nelement() > 0:\n",
    "            _log_ranks_for_epoch(model, fixed_val_images, epoch + 1, model_config_name, all_rank_data)\n",
    "\n",
    "    print(f\"Finished training for {model_config_name}\")\n",
    "    return pd.DataFrame(all_rank_data)\n",
    "\n",
    "# --- 5. Main Experiment Orchestration ---\n",
    "def run_main_experiment(\n",
    "    num_epochs=10, log_rank_every_n_epochs=1, mlp_hidden_layers=[256, 128], \n",
    "    activation_name=\"relu\", dropout_p=0.1, learning_rate=1e-3,\n",
    "    batch_size=256, rank_eval_batch_size_config=512\n",
    "    ):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n",
    "    try: train_loader, val_loader = get_cifar10_dataloaders(batch_size=batch_size)\n",
    "    except Exception as e: print(f\"Failed to load CIFAR-10: {e}. Aborting.\"); return\n",
    "\n",
    "    input_dim = 32 * 32 * 3; num_classes = 10\n",
    "    layer_dims_template = [input_dim] + mlp_hidden_layers + [num_classes]\n",
    "\n",
    "    configurations = {\n",
    "        \"MLP NoNorm\": {\"norm_type\": None},\n",
    "        \"MLP BatchNorm\": {\"norm_type\": \"batchnorm\"},\n",
    "        \"MLP LayerNorm\": {\"norm_type\": \"layernorm\"}\n",
    "    }\n",
    "    all_experimental_rank_data = []\n",
    "    # To get consistent layer stage names for plotting x-axis later\n",
    "    sample_model_for_layer_names = ConfigurableMLP(layer_dims_template, activation_name, None, 0.0)\n",
    "    plot_layer_stage_names = sample_model_for_layer_names.layer_stage_names\n",
    "    del sample_model_for_layer_names\n",
    "\n",
    "\n",
    "    for config_name, params in configurations.items():\n",
    "        print(f\"\\n--- Running Configuration: {config_name} ---\")\n",
    "        model = ConfigurableMLP(layer_dims_template, activation_name, params[\"norm_type\"], dropout_p).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate); criterion = nn.CrossEntropyLoss()\n",
    "        rank_data_df = train_model_with_rank_logging(\n",
    "            config_name, model, train_loader, val_loader, optimizer, criterion, \n",
    "            num_epochs, device, log_rank_every_n_epochs, rank_eval_batch_size_config\n",
    "        )\n",
    "        all_experimental_rank_data.append(rank_data_df)\n",
    "        del model; \n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    if not all_experimental_rank_data or all(df.empty for df in all_experimental_rank_data):\n",
    "        print(\"No rank data. Exiting plot.\"); return\n",
    "    final_rank_df = pd.concat(all_experimental_rank_data, ignore_index=True)\n",
    "\n",
    "    # --- 6. Visualization ---\n",
    "    # MODIFIED: Reversing the role of epochs and model configurations\n",
    "    if final_rank_df.empty: \n",
    "        print(\"Final rank df empty. Skipping plot.\")\n",
    "        return\n",
    "        \n",
    "    # Get unique epochs and select a subset (initial, middle, final)\n",
    "    unique_epochs = sorted(final_rank_df['epoch'].dropna().unique())\n",
    "    if not unique_epochs: \n",
    "        print(\"No epochs in data. Skipping plot.\")\n",
    "        return\n",
    "    \n",
    "    # Select only 3 epochs: initial (0), middle, and final\n",
    "    if len(unique_epochs) <= 3:\n",
    "        epochs_to_plot = unique_epochs\n",
    "    else:\n",
    "        middle_idx = len(unique_epochs) // 2\n",
    "        epochs_to_plot = [unique_epochs[0], unique_epochs[middle_idx], unique_epochs[-1]]\n",
    "    \n",
    "    # Create subplots for each selected epoch\n",
    "    num_epoch_subplots = len(epochs_to_plot)\n",
    "    fig, axs = plt.subplots(num_epoch_subplots, 1, figsize=(12, 5 * num_epoch_subplots), sharex=True, sharey=True)\n",
    "    if num_epoch_subplots == 1: \n",
    "        axs = [axs]  # Ensure axs is always a list\n",
    "    \n",
    "    # Define specific colors for each model configuration\n",
    "    config_colors = {\n",
    "        \"MLP NoNorm\": \"black\",\n",
    "        \"MLP BatchNorm\": \"blue\",\n",
    "        \"MLP LayerNorm\": \"red\"\n",
    "    }\n",
    "    \n",
    "    # Map layer names to integer indices for consistent plotting on x-axis\n",
    "    layer_name_to_idx = {name: i for i, name in enumerate(plot_layer_stage_names)}\n",
    "    \n",
    "    # Plot each epoch as a separate subplot\n",
    "    for i, epoch in enumerate(epochs_to_plot):\n",
    "        ax = axs[i]\n",
    "        epoch_data = final_rank_df[final_rank_df['epoch'] == epoch]\n",
    "        \n",
    "        if epoch_data.empty:\n",
    "            ax.set_title(f\"Epoch {epoch} (No Data)\")\n",
    "            continue\n",
    "        \n",
    "        # Plot each model configuration with its specific color\n",
    "        for config_name, color in config_colors.items():\n",
    "            config_epoch_data = epoch_data[epoch_data['model_config'] == config_name].copy()\n",
    "            \n",
    "            if not config_epoch_data.empty:\n",
    "                # Map layer names to their pre-defined indices for x-axis\n",
    "                config_epoch_data['plot_x_idx'] = config_epoch_data['layer_name'].map(layer_name_to_idx)\n",
    "                config_epoch_data.sort_values(by='plot_x_idx', inplace=True)\n",
    "                \n",
    "                # Filter out rows where plot_x_idx might be NaN\n",
    "                config_epoch_data_plot = config_epoch_data.dropna(subset=['plot_x_idx', 'eff_rank'])\n",
    "                \n",
    "                if not config_epoch_data_plot.empty:\n",
    "                    ax.plot(\n",
    "                        config_epoch_data_plot['plot_x_idx'], \n",
    "                        config_epoch_data_plot['eff_rank'],\n",
    "                        color=color,\n",
    "                        linestyle='-', \n",
    "                        marker='o', \n",
    "                        alpha=0.8,  # Slightly increased alpha for better visibility\n",
    "                        markersize=5,\n",
    "                        label=config_name  # Label lines with config names\n",
    "                    )\n",
    "        \n",
    "        ax.set_title(f\"Effective Rank at Epoch {epoch} (Activation: {activation_name.upper()})\")\n",
    "        ax.set_ylabel(\"Effective Rank\")\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.legend(loc='best')  # Add legend to each subplot\n",
    "        \n",
    "        if i == num_epoch_subplots - 1:  # X-axis labels only on the last subplot\n",
    "            ax.set_xticks(list(layer_name_to_idx.values()))\n",
    "            ax.set_xticklabels([name.replace(\"_\", \" \") for name in plot_layer_stage_names], rotation=45, ha='right')\n",
    "            ax.set_xlabel(\"Layer Stage\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.suptitle(f\"Effective Rank Comparison Across Model Configurations by Epoch\", y=0.99)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_main_experiment(\n",
    "        num_epochs=50,            \n",
    "        log_rank_every_n_epochs=1, \n",
    "        mlp_hidden_layers=[256]*5, # Smaller for quicker test\n",
    "        activation_name=\"relu\",   \n",
    "        dropout_p=0.0, # No dropout for clearer rank signal initially\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=256,\n",
    "        rank_eval_batch_size_config=512 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
