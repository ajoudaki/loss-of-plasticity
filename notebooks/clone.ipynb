{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amir/Codes/NN-dynamic-scaling already in Python path\n",
      "Cloning module \n",
      "Unsupported module type: <class 'src.models.mlp.MLP'>\n",
      "Cloning module layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.linear_0\n",
      "Cloning Linear module: 10→10, 64→128, in expansion: 1, out expansion: 2\n",
      "Cloning module layers.act_0\n",
      "Cloning module layers.linear_1\n",
      "Cloning Linear module: 64→128, 32→64, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.act_1\n",
      "Cloning module layers.out\n",
      "Cloning Linear module: 32→64, 2→2, in expansion: 2, out expansion: 1\n",
      "All activations match after cloning up to tolerance 0.001\n",
      "Replaced Flatten with CloneAwareFlatten at layers.flatten\n",
      "Cloning module \n",
      "Unsupported module type: <class 'src.models.cnn.CNN'>\n",
      "Cloning module layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.conv_0\n",
      "Cloning Conv2d module: 3→3, 64→128, in expansion: 1, out expansion: 2\n",
      "Cloning module layers.norm_0\n",
      "Cloning module layers.act_0\n",
      "Cloning module layers.pool_0\n",
      "Cloning module layers.conv_1\n",
      "Cloning Conv2d module: 64→128, 128→256, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.norm_1\n",
      "Cloning module layers.act_1\n",
      "Cloning module layers.pool_1\n",
      "Cloning module layers.conv_2\n",
      "Cloning Conv2d module: 128→256, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.norm_2\n",
      "Cloning module layers.act_2\n",
      "Cloning module layers.pool_2\n",
      "Cloning module layers.flatten\n",
      "Cloning module layers.fc_0\n",
      "Cloning Linear module: 4096→8192, 512→512, in expansion: 2, out expansion: 1\n",
      "Cloning module layers.fc_act_0\n",
      "Cloning module layers.fc_out\n",
      "Cloning Linear module: 512→512, 2→2, in expansion: 1, out expansion: 1\n",
      "All activations match after cloning up to tolerance 0.001\n",
      "Replaced Flatten with CloneAwareFlatten at layers.flatten\n",
      "Cloning module \n",
      "Unsupported module type: <class 'src.models.resnet.ResNet'>\n",
      "Cloning module layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.conv1\n",
      "Cloning Conv2d module: 3→3, 64→128, in expansion: 1, out expansion: 2\n",
      "Cloning module layers.bn1\n",
      "Cloning module layers.activation\n",
      "Cloning module layers.layer1_block0\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer1_block0.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer1_block0.layers.conv1\n",
      "Cloning Conv2d module: 64→128, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer1_block0.layers.bn1\n",
      "Cloning module layers.layer1_block0.layers.activation\n",
      "Cloning module layers.layer1_block0.layers.conv2\n",
      "Cloning Conv2d module: 64→128, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer1_block0.layers.bn2\n",
      "Cloning module layers.layer1_block1\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer1_block1.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer1_block1.layers.conv1\n",
      "Cloning Conv2d module: 64→128, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer1_block1.layers.bn1\n",
      "Cloning module layers.layer1_block1.layers.activation\n",
      "Cloning module layers.layer1_block1.layers.conv2\n",
      "Cloning Conv2d module: 64→128, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer1_block1.layers.bn2\n",
      "Cloning module layers.layer2_block0\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer2_block0.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer2_block0.layers.conv1\n",
      "Cloning Conv2d module: 64→128, 128→256, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer2_block0.layers.bn1\n",
      "Cloning module layers.layer2_block0.layers.activation\n",
      "Cloning module layers.layer2_block0.layers.conv2\n",
      "Cloning Conv2d module: 128→256, 128→256, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer2_block0.layers.bn2\n",
      "Cloning module layers.layer2_block0.layers.downsample\n",
      "Unsupported module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "Cloning module layers.layer2_block0.layers.downsample.0\n",
      "Cloning Conv2d module: 64→128, 128→256, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer2_block0.layers.downsample.1\n",
      "Cloning module layers.layer2_block1\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer2_block1.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer2_block1.layers.conv1\n",
      "Cloning Conv2d module: 128→256, 128→256, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer2_block1.layers.bn1\n",
      "Cloning module layers.layer2_block1.layers.activation\n",
      "Cloning module layers.layer2_block1.layers.conv2\n",
      "Cloning Conv2d module: 128→256, 128→256, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer2_block1.layers.bn2\n",
      "Cloning module layers.layer3_block0\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer3_block0.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer3_block0.layers.conv1\n",
      "Cloning Conv2d module: 128→256, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer3_block0.layers.bn1\n",
      "Cloning module layers.layer3_block0.layers.activation\n",
      "Cloning module layers.layer3_block0.layers.conv2\n",
      "Cloning Conv2d module: 256→512, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer3_block0.layers.bn2\n",
      "Cloning module layers.layer3_block0.layers.downsample\n",
      "Unsupported module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "Cloning module layers.layer3_block0.layers.downsample.0\n",
      "Cloning Conv2d module: 128→256, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer3_block0.layers.downsample.1\n",
      "Cloning module layers.layer3_block1\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer3_block1.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer3_block1.layers.conv1\n",
      "Cloning Conv2d module: 256→512, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer3_block1.layers.bn1\n",
      "Cloning module layers.layer3_block1.layers.activation\n",
      "Cloning module layers.layer3_block1.layers.conv2\n",
      "Cloning Conv2d module: 256→512, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer3_block1.layers.bn2\n",
      "Cloning module layers.layer4_block0\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer4_block0.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer4_block0.layers.conv1\n",
      "Cloning Conv2d module: 256→512, 512→1024, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer4_block0.layers.bn1\n",
      "Cloning module layers.layer4_block0.layers.activation\n",
      "Cloning module layers.layer4_block0.layers.conv2\n",
      "Cloning Conv2d module: 512→1024, 512→1024, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer4_block0.layers.bn2\n",
      "Cloning module layers.layer4_block0.layers.downsample\n",
      "Unsupported module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "Cloning module layers.layer4_block0.layers.downsample.0\n",
      "Cloning Conv2d module: 256→512, 512→1024, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer4_block0.layers.downsample.1\n",
      "Cloning module layers.layer4_block1\n",
      "Unsupported module type: <class 'src.models.resnet.BasicBlock'>\n",
      "Cloning module layers.layer4_block1.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.layer4_block1.layers.conv1\n",
      "Cloning Conv2d module: 512→1024, 512→1024, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer4_block1.layers.bn1\n",
      "Cloning module layers.layer4_block1.layers.activation\n",
      "Cloning module layers.layer4_block1.layers.conv2\n",
      "Cloning Conv2d module: 512→1024, 512→1024, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.layer4_block1.layers.bn2\n",
      "Cloning module layers.avgpool\n",
      "Cloning module layers.flatten\n",
      "Cloning module layers.fc\n",
      "Cloning Linear module: 512→1024, 2→2, in expansion: 2, out expansion: 1\n",
      "All activations match after cloning up to tolerance 0.001\n",
      "Cloned parameter cls_token with embedding expansion 2\n",
      "Cloned parameter pos_embed with embedding expansion 2\n",
      "Cloning module \n",
      "Unsupported module type: <class 'src.models.vit.VisionTransformer'>\n",
      "Cloning module layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.patch_embed\n",
      "Unsupported module type: <class 'src.models.vit.PatchEmbedding'>\n",
      "Cloning module layers.patch_embed.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.patch_embed.layers.proj\n",
      "Cloning Conv2d module: 3→3, 64→128, in expansion: 1, out expansion: 2\n",
      "Cloning module layers.pos_drop\n",
      "Cloning module layers.block_0\n",
      "Unsupported module type: <class 'src.models.vit.TransformerBlock'>\n",
      "Cloning module layers.block_0.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.block_0.layers.norm1\n",
      "Cloning module layers.block_0.layers.attn\n",
      "Unsupported module type: <class 'src.models.vit.Attention'>\n",
      "Cloning module layers.block_0.layers.attn.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.block_0.layers.attn.layers.qkv\n",
      "Cloning Linear module: 64→128, 192→384, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_0.layers.attn.layers.attn_drop\n",
      "Cloning module layers.block_0.layers.attn.layers.proj\n",
      "Cloning Linear module: 64→128, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_0.layers.attn.layers.proj_drop\n",
      "Cloning module layers.block_0.layers.norm2\n",
      "Cloning module layers.block_0.layers.mlp\n",
      "Unsupported module type: <class 'src.models.vit.TransformerMLP'>\n",
      "Cloning module layers.block_0.layers.mlp.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.block_0.layers.mlp.layers.fc1\n",
      "Cloning Linear module: 64→128, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_0.layers.mlp.layers.act\n",
      "Cloning module layers.block_0.layers.mlp.layers.drop1\n",
      "Cloning module layers.block_0.layers.mlp.layers.fc2\n",
      "Cloning Linear module: 256→512, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_0.layers.mlp.layers.drop2\n",
      "Cloning module layers.block_1\n",
      "Unsupported module type: <class 'src.models.vit.TransformerBlock'>\n",
      "Cloning module layers.block_1.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.block_1.layers.norm1\n",
      "Cloning module layers.block_1.layers.attn\n",
      "Unsupported module type: <class 'src.models.vit.Attention'>\n",
      "Cloning module layers.block_1.layers.attn.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.block_1.layers.attn.layers.qkv\n",
      "Cloning Linear module: 64→128, 192→384, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_1.layers.attn.layers.attn_drop\n",
      "Cloning module layers.block_1.layers.attn.layers.proj\n",
      "Cloning Linear module: 64→128, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_1.layers.attn.layers.proj_drop\n",
      "Cloning module layers.block_1.layers.norm2\n",
      "Cloning module layers.block_1.layers.mlp\n",
      "Unsupported module type: <class 'src.models.vit.TransformerMLP'>\n",
      "Cloning module layers.block_1.layers.mlp.layers\n",
      "Unsupported module type: <class 'torch.nn.modules.container.ModuleDict'>\n",
      "Cloning module layers.block_1.layers.mlp.layers.fc1\n",
      "Cloning Linear module: 64→128, 256→512, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_1.layers.mlp.layers.act\n",
      "Cloning module layers.block_1.layers.mlp.layers.drop1\n",
      "Cloning module layers.block_1.layers.mlp.layers.fc2\n",
      "Cloning Linear module: 256→512, 64→128, in expansion: 2, out expansion: 2\n",
      "Cloning module layers.block_1.layers.mlp.layers.drop2\n",
      "Cloning module layers.norm\n",
      "Cloning module layers.head\n",
      "Cloning Linear module: 64→128, 2→2, in expansion: 2, out expansion: 1\n",
      "All activations match after cloning up to tolerance 0.01\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c153e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
